{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ae6dd9",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8a1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0157eb",
   "metadata": {},
   "source": [
    "## <font color = brown> Pre-processing of training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6e9a2",
   "metadata": {},
   "source": [
    "#### Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c41318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\loan_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4270a8",
   "metadata": {},
   "source": [
    "#### Loading the head of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585dc921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9f89d",
   "metadata": {},
   "source": [
    "#### Getting the shape of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe88accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03072368",
   "metadata": {},
   "source": [
    "#### Getting the info of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80818580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c60eb",
   "metadata": {},
   "source": [
    "#### Finding the null values in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b8cbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286af0d",
   "metadata": {},
   "source": [
    "###### <font color = violet> There are null values in 7 columns of the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fe957",
   "metadata": {},
   "source": [
    "#### Finding the unique values in the column \"Dependents\" in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53689a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3+', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Dependents.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837dd348",
   "metadata": {},
   "source": [
    "#### Displaying the distribution of float-datatype columns that contain null values in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b1519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    plt.hist(df_train[i])\n",
    "    plt.title('Distribution of {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512a8e6",
   "metadata": {},
   "source": [
    "###### <font color = violet> We can see that all the three float-datatype columns that contain null values of the training dataset have about skewed distribution. So we can fill the null values in these columns with their respective medians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fe8f4",
   "metadata": {},
   "source": [
    "#### Filling the null values of the float-datatype columns of the training dataset by their respective medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db9a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    df_train[j].fillna(df_train[j].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88917c",
   "metadata": {},
   "source": [
    "#### Filling the null values of the string-datatype columns of the training dataset by their respective mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['Gender', 'Married', 'Dependents', 'Self_Employed']:\n",
    "    df_train[k].fillna(df_train[k].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de670998",
   "metadata": {},
   "source": [
    "#### Finding whether there is any more null values in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b0bd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4f2b2",
   "metadata": {},
   "source": [
    "#### Displaying the statistical summary of the taining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db1374f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>145.752443</td>\n",
       "      <td>342.410423</td>\n",
       "      <td>0.855049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>84.107233</td>\n",
       "      <td>64.428629</td>\n",
       "      <td>0.352339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  614.000000        614.000000   \n",
       "mean       5403.459283        1621.245798  145.752443        342.410423   \n",
       "std        6109.041673        2926.248369   84.107233         64.428629   \n",
       "min         150.000000           0.000000    9.000000         12.000000   \n",
       "25%        2877.500000           0.000000  100.250000        360.000000   \n",
       "50%        3812.500000        1188.500000  128.000000        360.000000   \n",
       "75%        5795.000000        2297.250000  164.750000        360.000000   \n",
       "max       81000.000000       41667.000000  700.000000        480.000000   \n",
       "\n",
       "       Credit_History  \n",
       "count      614.000000  \n",
       "mean         0.855049  \n",
       "std          0.352339  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083d153",
   "metadata": {},
   "source": [
    "#### Finding outliers in the numerical columns of the training dataset using boxplot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42594a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGxCAYAAABr1xxGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz7ElEQVR4nO3de3hU9b3v8U8uZAgxmU2IySSCEg0I7gSqsUWgkZtykYAU2XQ3mOouxQsiRqGeYveul12BCoLtQyliW91uLfEUAscNGKEVMEhQDOZIBCp6uJMQimESICQh+Z0/1pMJkwRMAB3yy/v1PPOErPWdNd81M7o++a31mwkyxhgBAABYKDjQDQAAAHxTCDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOmhfXntNCgryv119tTR4sLR6daC7a9C9u3T//a2/3+nT0jPPSBs3Xt5+JGnfPmn0aCk62nnesrIuXF9VJS1aJH3/+1LnzlJYmHTNNdLEidKmTZe/v2/a/fc7r8u5LvZ1utx27nRe9337mq67/37pqqu+5YaAK0dooBsAAuLVV6VevSRjpJIS54A8Zoz09tvOz7bq9Gnp2Wedfw8efHm3/fjj0ocfSn/6k+TxSPHx56/9xz+kkSOlTz+VfvIT6Wc/cwLS4cPS//k/0rBhUkGB1Lfv5e3x27ZypRQVFegunKDz7LPOa944jAHtHEEH7VNysnTrrQ2/jxzpjDosW9a2g843qahI+t73pHHjvr72xz+W/u//ld59Vxo61H/dv/6r9MQTzvPd1t18c6A7APA1OHUFSFLHjs6plQ4d/Jd/9ZU0dapzyiUsTLr+eukXv3BOy0jSmTPOwS4pSfJ6G+5XUuKMegweLNXWOsvqTyF89pkzohER4Zw2mzbNGYn5OgcOSPfeK8XGSi6X1Lu39OKLUl2ds37fPmd7kvPXff2pua87tfJ129240dnOF19I77zTsN3mTpNIzkjNO+9Ikyc3DTn1vvtd6dprG34vKpLuvtsJPx07St/5jvRf/+V/nzNnpBkznHVutzNC1L+/M0LUWFCQ87y+/LLUs6ezXzfdJGVn+9fVn8pcv176t39zthkR4YTd//f/Lvy8Sc2fujpxwunz+uudx42Nle66S9q9u6Hm2Welfv2cx4uKkm65RfrjH50RxsbbT0+XcnOdmvBwZyTyT3/y34d/+Rfn30OGNLw+r7124b6/brv1Dh+WHnhA6tbN+W8gIUGaMEE6erSh5uveQ5LzfgkKkubNk379a6eH8HDnv5HPP5dqaqSf/9zZvtst/eAHUmlp037eest53SMinP+eRoyQPvnk/PsKGKA9efVVYyRjtm41pqbGmOpqYw4eNGb6dGOCg43JzW2oraw0pk8fYyIijJk/35h164z5j/8wJjTUmLvuaqj7/HNjIiONGT/e+b221pihQ42JjTXmyJGGuvvuMyYszJhrrzXm+eed7T3zjLO99HT/Pq+7zqmvV1pqzDXXGHP11cYsWeL0OW2asy8PP+zUnDnjLJeMmTzZmPx85/bFF+d/PlqyXa/X2Y7HY8zAgQ3bPXOm+W3Onu3c/513zv+459q923n+brjBmNdfN2bNGmN+9CNnG7/+dUPdiRPG3H+/Mf/938a8957T68yZzuv2X//lv03JmG7djLnpJmOWLTPm7beNGTnSWf6XvzTU1b8funUz5ic/cXpeutR57bp1M6asrKH2vvuc1+VcjV+n8nJj/vmfnffMc88Z8+67xqxYYcxjjzk917v/fmP++Edj1q93bv/5n8aEhxvz7LNNt9+1q7Mfr7/ubO9f/sXpedMmp6a0tOE5/93vGl6f0tKGviMiWr9dY4w5dMiY+HhjYmKMWbDAmL/+1Zi33nKeq127Gh7/695Dxhizd6+z7LrrjBkzxpjVq4154w1j4uKM6dnTmMzMhtdgyRJjrrrKqTvX888bExTk1K1ebUxOjjH9+zv799lnBmgOQQftS/2BrfHN5TJm8WL/2iVLnHX/+3/7L//1r53l69Y1LHvrLWfZSy8Z88tfOgffc9cb4xxwJGN+8xv/5c8/7yzfvLlhWeMD6M9/7tR8+KH/fR9+2Pkf/9//7vx+7JhT9/TTLXo6Wrzd+p5Gj/76bT70kLPN3btb1sO//qvz/B844L981ChjOnVyAk5zzp51wurkycbcfLP/OskJDiUl/vW9ehmTlNSwrP798IMf+N//gw+c5b/6VcOylgSd555z7rd+/Xl3t4naWmc/nnvOmC5djKmr899+x47G7N/fsKyy0pjoaGMefLBh2V/+4jzuhg1Nt3++oNOS7f7kJ8Z06GDMzp3n77+l76H6oNO3r7PP9V56yVk+dqz//bOynOVer/P7gQPOHwWPPupfV1HhhPCJE8/fI9o1Tl2hfXr9dWnbNuf2zjvSffdJjzziXJRc7733nOHxCRP871t/quJvf2tYNnGi9PDDzkW3v/qV9NRT0p13Nv/Ykyb5/56R4fzcsOH8/b73nnPq5Xvfa9qLMc76i/FNbbe1PQwb5pwaadzD6dNSfn7Dsr/8RRo40DllERrqnGr84x+lXbuabnfYMCkuruH3kBDphz90TsEdOuRf2/g1GTBAuu66C78mzXnnHedU2R13XLjuvfecGrfb6atDB+mXv5SOH296uuY73/E/zdexo/MY+/e3rrfGWrLdd95xTof17n3hfWnNe+iuu6Tgcw499dsePdq/rn75gQPOz3fflc6eda7/Onu24daxozRo0Dcz0xBWIOigferd27kY+dZbnQuRX35ZGj5cevJJ5xoLyTnoeDzOdQXnio11DrLHj/sv/8lPnOsMQkOl6dObf9zQUKlLF/9lHk/D453P8ePNz3JKSPj6+17IN7Hd+oPn3r2Xt4ecHCdQXnON9MYbTgDats153s+caXr/+ue1uWWN9+t8ta3d/2PHpK5dL1zz0UfOe02SXnlF+uADZz9+8QtnWWWlf33j94vkXAfTuK61WrLdluxPa99D0dH+v4eFXXh5/Wtbf03Qd7/rBMNzb2+95cz0A5rBrCugXp8+zl+Nn3/u/HXapYszndoY/7BTWur8JRkT07Ds1CkpM9P5i/joUemnP23+ItmzZ53/8Z97kCkpcX42d+Cp16WLVFzcdPmRI87Pc3tpjW9iuyNGOCNaq1Y5IfJy9fDGG1JionNQO/f1qL8wvLH657W5ZY2f6/PVJiVduPfGrr666WhRY9nZzsF59WpnNKLeqlWte6xvQ0v255t6bzZWv53ly53RNqCFGNEB6hUWOj/rZy4NGyadPNn0APT66w3r6z30kDPEnpPjnEp5+21p4cLmH+fNN/1///OfnZ8X+tybYcOcz0rZvr1pL0FBzukFyfmLXGr5X/st3W5r3HKLNGqU8zyc79TXxx83nJIYNsypqz8wnttDp07Sbbc5vwcFOX/lnxtySkqaD5SSc2rx3JlBtbVOSLrhhqajFI1fky1bnFM4rf0solGjnKB8oVN+QUHOyF5ISMOyykrpv/+7dY91rta+7i01apRz+u7vfz9/zTfxHmrOiBHO8/bllw2jsY1vQDMY0UH7VFTkjK5IzghLTo4zxfgHP3BGDSTnWoDf/c65fmffPiklRdq8WZo927nOoP46jD/8wRltePVV6Z//2blNmyb9r//lXE9y7rULYWHOtNuTJ50h+C1bnGt6Ro1yPkH4fB5/3DlwjB4tPfec8xftmjXS4sXOtUE9ezp1kZHOuvoP5YuOdv4SPt+HyLV0u631+uvOaM6oUc6ppVGjnKnjxcXS//yP83lFBQXOaa6nn3ZGN4YMca5TiY52gseaNdILLzjXsUjOdOicHGe6/4QJ0sGD0n/+p3PaZM+epj3ExDjT2//jP5xrrRYvdqZ4N55iLjnB66c/daZpHzzonEa65hrnsVojK8sJU3ff7UyV/t73nPCxaZPT/5AhznO9YIFzbdYDDzjvv/nzG8LKxUhOdn4uXeq8Bzp2dN7HFxolbInnnnOu07n9dmeULiXFObWbm+t8FlKvXt/ce6ix7t2d7f/iF87U//rPvjp61DkdGBHR8GGZwLkCfTU08K1qbtaV223Md77jTJ9tPGX6+HFnFlF8vDPj47rrjJk1q6Hu00+d2T3nzrwxxlmfmmpM9+4NU5TrZ798+qkxgwc794uOdmannDzpf//Gs3mMcWbIZGQ4M3M6dDDmxhuNmTfPfwaLMc4U4JtvdmYySU2301hLt9vSWVf1KiuN+e1vnem/UVHO85eQ4EzDX7PGv3bHDmcqsdvtTMHv29d5rRqbO9d5Tl0uY3r3NuaVV5wZZo3/VyYZ88gjzky6G25w9qtXL2PefNO/rv79sG6dM735n/7JeV3uusuYPXv8a1sy68oY5/V+7DHnYwQ6dHCmqo8e7T8L7U9/cp5nl8uY6683Zs4cZ7q55MxOOnf7zT3ngwY5t3O99JIxiYnGhIQ426l//s4366ql2z140Jl95fE4+5OQ4MxwOnq0oaYl76H6WVfz5vlvf8OGptP+jWl4bbZt81++apUxQ4Y47ymXy9mXCROc9z3QjCBjGn9CFYBvxP33O9cXnDwZ6E7sFxTUdBZdc157zfmgwG3bOPUBWIprdAAAgLUIOgAAwFqcugIAANZiRAcAAFiLoAMAAKxF0AEAANZq1x8YWFdXpyNHjigyMlJBjb/PCAAAXJGMMaqoqFBCQoKCgy88ZtOug86RI0fUrfE3JgMAgDbh4MGD6vo1XzzbroNOZGSkJOeJioqKCnA3AACgJcrLy9WtWzffcfxC2nXQqT9dFRUVRdABAKCNacllJ1yMDAAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYq11/YCAAO9XW1iovL0/FxcWKj49XWlqaQkJCAt0WgABgRAeAVXJycpSUlKQhQ4YoIyNDQ4YMUVJSknJycgLdGoAAIOgAsEZOTo4mTJiglJQU5efnq6KiQvn5+UpJSdGECRMIO0A7FGSMMYFuIlDKy8vldrvl9Xr5riugjautrVVSUpJSUlK0atUqBQc3/B1XV1encePGqaioSHv27OE0FtDGteb4zYgOACvk5eVp3759euqpp/xCjiQFBwdr1qxZ2rt3r/Ly8gLUIYBAIOgAsEJxcbEkKTk5udn19cvr6wC0DwQdAFaIj4+XJBUVFTW7vn55fR2A9oGgA8AKaWlp6t69u2bPnq26ujq/dXV1dZozZ44SExOVlpYWoA4BBAJBB4AVQkJC9OKLL2r16tUaN26c36yrcePGafXq1Zo/fz4XIgPtDB8YCMAa48eP1/LlyzVjxgwNGDDAtzwxMVHLly/X+PHjA9gdgEBgejnTywHr8MnIgN1ac/xmRAeAdUJCQjR48OBAtwHgCsA1OgAAwFoEHQAAYC2CDgAAsNYlBZ05c+YoKChIWVlZvmXGGD3zzDNKSEhQeHi4Bg8erM8++8zvflVVVXr00UcVExOjiIgIjR07VocOHfKrKSsrU2Zmptxut9xutzIzM3XixAm/mgMHDmjMmDGKiIhQTEyMpk+frurq6kvZJQAAYJGLDjrbtm3T0qVL1adPH7/lL7zwghYsWKBFixZp27Zt8ng8uvPOO1VRUeGrycrK0sqVK5Wdna3Nmzfr5MmTSk9PV21tra8mIyNDhYWFys3NVW5urgoLC5WZmelbX1tbq9GjR+vUqVPavHmzsrOztWLFCs2YMeNidwkAANjGXISKigrTo0cPs379ejNo0CDz2GOPGWOMqaurMx6Px8ydO9dXe+bMGeN2u82SJUuMMcacOHHCdOjQwWRnZ/tqDh8+bIKDg01ubq4xxpidO3caSWbr1q2+mvz8fCPJ7N692xhjzNq1a01wcLA5fPiwr2bZsmXG5XIZr9fbov3wer1GUovrAQBA4LXm+H1RIzqPPPKIRo8erTvuuMNv+d69e1VSUqLhw4f7lrlcLg0aNEhbtmyRJBUUFKimpsavJiEhQcnJyb6a/Px8ud1u9evXz1dz2223ye12+9UkJycrISHBVzNixAhVVVWpoKCg2b6rqqpUXl7udwMAAPZq9efoZGdna/v27dq2bVuTdSUlJZKkuLg4v+VxcXHav3+/ryYsLEydO3duUlN//5KSEsXGxjbZfmxsrF9N48fp3LmzwsLCfDWNzZkzR88++2xLdhMAAFigVSM6Bw8e1GOPPaY33nhDHTt2PG9dUFCQ3+/GmCbLGmtc01z9xdSca9asWfJ6vb7bwYMHL9gTAABo21oVdAoKClRaWqrU1FSFhoYqNDRUmzZt0m9/+1uFhob6Rlgaj6iUlpb61nk8HlVXV6usrOyCNUePHm3y+MeOHfOrafw4ZWVlqqmpaTLSU8/lcikqKsrvBgAA7NWqoDNs2DDt2LFDhYWFvtutt96qSZMmqbCwUNdff708Ho/Wr1/vu091dbU2bdrk+4K91NRUdejQwa+muLhYRUVFvpr+/fvL6/Xqo48+8tV8+OGH8nq9fjVFRUUqLi721axbt04ul0upqakX8VQAAADbtOoancjISCUnJ/sti4iIUJcuXXzLs7KyNHv2bPXo0UM9evTQ7Nmz1alTJ2VkZEiS3G63Jk+erBkzZqhLly6Kjo7WzJkzlZKS4ru4uXfv3ho5cqSmTJmil19+WZL0wAMPKD09XTfeeKMkafjw4brpppuUmZmpefPm6auvvtLMmTM1ZcoURmoAAICkb+BLPZ988klVVlZq6tSpKisrU79+/bRu3TpFRkb6ahYuXKjQ0FBNnDhRlZWVGjZsmF577TW/bxd+8803NX36dN/srLFjx2rRokW+9SEhIVqzZo2mTp2qgQMHKjw8XBkZGZo/f/7l3iUAANBGBRljTKCbCJTWfM07AAC4MrTm+M13XQEAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYKzTQDQDA5VZbW6u8vDwVFxcrPj5eaWlpCgkJCXRbAAKAER0AVsnJyVFSUpKGDBmijIwMDRkyRElJScrJyQl0awACgKADwBo5OTmaMGGCUlJSlJ+fr4qKCuXn5yslJUUTJkwg7ADtUJAxxgS6iUApLy+X2+2W1+tVVFRUoNsBcAlqa2uVlJSklJQUrVq1SsHBDX/H1dXVady4cSoqKtKePXs4jQW0ca05fjOiA8AKeXl52rdvn5566im/kCNJwcHBmjVrlvbu3au8vLwAdQggEAg6AKxQXFwsSUpOTm52ff3y+joA7QNBB4AV4uPjJUlFRUXNrq9fXl8HoH0g6ACwQlpamrp3767Zs2errq7Ob11dXZ3mzJmjxMREpaWlBahDAIFA0AFghZCQEL344otavXq1xo0b5zfraty4cVq9erXmz5/PhchAO8MHBgKwxvjx47V8+XLNmDFDAwYM8C1PTEzU8uXLNX78+AB2ByAQmF7O9HLAOnwyMmC31hy/GdEBYJ2QkBANHjw40G0AuAJwjQ4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWalXQ+f3vf68+ffooKipKUVFR6t+/v9555x3femOMnnnmGSUkJCg8PFyDBw/WZ5995reNqqoqPfroo4qJiVFERITGjh2rQ4cO+dWUlZUpMzNTbrdbbrdbmZmZOnHihF/NgQMHNGbMGEVERCgmJkbTp09XdXV1K3cfAADYrFVBp2vXrpo7d64+/vhjffzxxxo6dKjuvvtuX5h54YUXtGDBAi1atEjbtm2Tx+PRnXfeqYqKCt82srKytHLlSmVnZ2vz5s06efKk0tPTVVtb66vJyMhQYWGhcnNzlZubq8LCQmVmZvrW19bWavTo0Tp16pQ2b96s7OxsrVixQjNmzLjU5wMAANjEXKLOnTubP/zhD6aurs54PB4zd+5c37ozZ84Yt9ttlixZYowx5sSJE6ZDhw4mOzvbV3P48GETHBxscnNzjTHG7Ny500gyW7du9dXk5+cbSWb37t3GGGPWrl1rgoODzeHDh301y5YtMy6Xy3i93hb37vV6jaRW3QcAAARWa47fF32NTm1trbKzs3Xq1Cn1799fe/fuVUlJiYYPH+6rcblcGjRokLZs2SJJKigoUE1NjV9NQkKCkpOTfTX5+flyu93q16+fr+a2226T2+32q0lOTlZCQoKvZsSIEaqqqlJBQcF5e66qqlJ5ebnfDQAA2KvVQWfHjh266qqr5HK59NBDD2nlypW66aabVFJSIkmKi4vzq4+Li/OtKykpUVhYmDp37nzBmtjY2CaPGxsb61fT+HE6d+6ssLAwX01z5syZ47vux+12q1u3bq3cewAA0Ja0OujceOONKiws1NatW/Xwww/rvvvu086dO33rg4KC/OqNMU2WNda4prn6i6lpbNasWfJ6vb7bwYMHL9gXAABo21oddMLCwpSUlKRbb71Vc+bMUd++ffWb3/xGHo9HkpqMqJSWlvpGXzwej6qrq1VWVnbBmqNHjzZ53GPHjvnVNH6csrIy1dTUNBnpOZfL5fLNGKu/AQAAe13y5+gYY1RVVaXExER5PB6tX7/et666ulqbNm3SgAEDJEmpqanq0KGDX01xcbGKiop8Nf3795fX69VHH33kq/nwww/l9Xr9aoqKilRcXOyrWbdunVwul1JTUy91lwAAgCVCW1P81FNPadSoUerWrZsqKiqUnZ2tjRs3Kjc3V0FBQcrKytLs2bPVo0cP9ejRQ7Nnz1anTp2UkZEhSXK73Zo8ebJmzJihLl26KDo6WjNnzlRKSoruuOMOSVLv3r01cuRITZkyRS+//LIk6YEHHlB6erpuvPFGSdLw4cN10003KTMzU/PmzdNXX32lmTNnasqUKYzSAAAAn1YFnaNHjyozM1PFxcVyu93q06ePcnNzdeedd0qSnnzySVVWVmrq1KkqKytTv379tG7dOkVGRvq2sXDhQoWGhmrixImqrKzUsGHD9NprrykkJMRX8+abb2r69Om+2Vljx47VokWLfOtDQkK0Zs0aTZ06VQMHDlR4eLgyMjI0f/78S3oyAACAXYKMMSbQTQRKeXm53G63vF4vI0EAALQRrTl+811XAADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWCs00A0AwOVWXV2txYsX68svv9QNN9ygqVOnKiwsLNBtAQiAVo3ozJkzR9/97ncVGRmp2NhYjRs3Tn//+9/9aowxeuaZZ5SQkKDw8HANHjxYn332mV9NVVWVHn30UcXExCgiIkJjx47VoUOH/GrKysqUmZkpt9stt9utzMxMnThxwq/mwIEDGjNmjCIiIhQTE6Pp06erurq6NbsEwDJPPvmkIiIi9Pjjj2vRokV6/PHHFRERoSeffDLQrQEIgFYFnU2bNumRRx7R1q1btX79ep09e1bDhw/XqVOnfDUvvPCCFixYoEWLFmnbtm3yeDy68847VVFR4avJysrSypUrlZ2drc2bN+vkyZNKT09XbW2tryYjI0OFhYXKzc1Vbm6uCgsLlZmZ6VtfW1ur0aNH69SpU9q8ebOys7O1YsUKzZgx41KeDwBt2JNPPql58+apS5cueuWVV1RcXKxXXnlFXbp00bx58wg7QHtkLkFpaamRZDZt2mSMMaaurs54PB4zd+5cX82ZM2eM2+02S5YsMcYYc+LECdOhQweTnZ3tqzl8+LAJDg42ubm5xhhjdu7caSSZrVu3+mry8/ONJLN7925jjDFr1641wcHB5vDhw76aZcuWGZfLZbxeb4v693q9RlKL6wFcuaqqqkxoaKiJi4szNTU1futqampMXFycCQ0NNVVVVQHqEMDl0prj9yVdjOz1eiVJ0dHRkqS9e/eqpKREw4cP99W4XC4NGjRIW7ZskSQVFBSopqbGryYhIUHJycm+mvz8fLndbvXr189Xc9ttt8ntdvvVJCcnKyEhwVczYsQIVVVVqaCgoNl+q6qqVF5e7ncDYIfFixfr7Nmz+tWvfqXQUP/LD0NDQ/Xcc8/p7NmzWrx4cYA6BBAIFx10jDF64okn9P3vf1/JycmSpJKSEklSXFycX21cXJxvXUlJicLCwtS5c+cL1sTGxjZ5zNjYWL+axo/TuXNnhYWF+WoamzNnju+aH7fbrW7durV2twFcob788ktJUnp6erPr65fX1wFoHy466EybNk2ffvqpli1b1mRdUFCQ3+/GmCbLGmtc01z9xdSca9asWfJ6vb7bwYMHL9gTgLbjhhtukCStXr262fX1y+vrALQPFxV0Hn30Ub399tvasGGDunbt6lvu8XgkqcmISmlpqW/0xePxqLq6WmVlZResOXr0aJPHPXbsmF9N48cpKytTTU1Nk5Geei6XS1FRUX43AHaYOnWqQkND9e///u86e/as37qzZ8/ql7/8pUJDQzV16tQAdQggEFoVdIwxmjZtmnJycvTee+8pMTHRb31iYqI8Ho/Wr1/vW1ZdXa1NmzZpwIABkqTU1FR16NDBr6a4uFhFRUW+mv79+8vr9eqjjz7y1Xz44Yfyer1+NUVFRSouLvbVrFu3Ti6XS6mpqa3ZLQAWCAsL0+OPP66jR4+qa9euWrp0qY4cOaKlS5eqa9euOnr0qB5//HE+Twdob1pzlfPDDz9s3G632bhxoykuLvbdTp8+7auZO3eucbvdJicnx+zYscP86Ec/MvHx8aa8vNxX89BDD5muXbuav/71r2b79u1m6NChpm/fvubs2bO+mpEjR5o+ffqY/Px8k5+fb1JSUkx6erpv/dmzZ01ycrIZNmyY2b59u/nrX/9qunbtaqZNm9bi/WHWFWCfn/3sZyY0NNRI8t1CQ0PNz372s0C3BuAyac3xu1VB59z/cZx7e/XVV301dXV15umnnzYej8e4XC5z++23mx07dvhtp7Ky0kybNs1ER0eb8PBwk56ebg4cOOBXc/z4cTNp0iQTGRlpIiMjzaRJk0xZWZlfzf79+83o0aNNeHi4iY6ONtOmTTNnzpxp8f4QdAA7VVVVmYULF5pp06aZhQsXMqUcsExrjt9BxhgTkKGkK0B5ebncbre8Xi/X6wAA0Ea05vjNl3oCAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLVCA90AAFxutbW1ysvLU3FxseLj45WWlqaQkJBAtwUgABjRAWCVnJwcJSUlaciQIcrIyNCQIUOUlJSknJycQLcGIAAIOgCskZOTowkTJiglJUX5+fmqqKhQfn6+UlJSNGHCBMIO0A4FGWNMoJsIlPLycrndbnm9XkVFRQW6HQCXoLa2VklJSUpJSdGKFSv0wQcf+E5dDRw4UPfcc4+Kioq0Z88eTmMBbVxrjt+M6ACwQl5envbt26cBAwaoZ8+efqeuevbsqf79+2vv3r3Ky8sLdKsAvkUEHQBWKC4uliTNmjWr2VNXTz31lF8dgPaBWVcArBAbGytJ+v73v69Vq1YpONj5O+62227TqlWrdPvtt+uDDz7w1QFoHxjRAdAuBAUFBboFAAFA0AFghdLSUknSBx98oHHjxvmduho3bpw++OADvzoA7QNBB4AV4uPjJUmzZ8/Wjh07NGDAAEVFRWnAgAEqKirS888/71cHoH3gGh0AVkhLS1P37t21ZcsWff75581OL09MTFRaWlqgWwXwLWJEB4AVQkJC9OKLL2r16tW655575HK5lJ6eLpfLpXvuuUerV6/W/Pnz+QwdoJ1pddB5//33NWbMGCUkJCgoKEirVq3yW2+M0TPPPKOEhASFh4dr8ODB+uyzz/xqqqqq9OijjyomJkYREREaO3asDh065FdTVlamzMxMud1uud1uZWZm6sSJE341Bw4c0JgxYxQREaGYmBhNnz5d1dXVrd0lAJYYP368li9f3uypq+XLl2v8+PGBbhHAt6zVQefUqVPq27evFi1a1Oz6F154QQsWLNCiRYu0bds2eTwe3XnnnaqoqPDVZGVlaeXKlcrOztbmzZt18uRJpaenq7a21leTkZGhwsJC5ebmKjc3V4WFhcrMzPStr62t1ejRo3Xq1Clt3rxZ2dnZWrFihWbMmNHaXQJgkfHjx+uLL77Qhg0b9Oc//1kbNmzQnj17CDlAe2UugSSzcuVK3+91dXXG4/GYuXPn+padOXPGuN1us2TJEmOMMSdOnDAdOnQw2dnZvprDhw+b4OBgk5uba4wxZufOnUaS2bp1q68mPz/fSDK7d+82xhizdu1aExwcbA4fPuyrWbZsmXG5XMbr9baof6/XayS1uB4AAARea47fl/Uanb1796qkpETDhw/3LXO5XBo0aJC2bNkiSSooKFBNTY1fTUJCgpKTk301+fn5crvd6tevn6/mtttuk9vt9qtJTk5WQkKCr2bEiBGqqqpSQUFBs/1VVVWpvLzc7wYAAOx1WYNOSUmJJCkuLs5veVxcnG9dSUmJwsLC1Llz5wvWNPfppbGxsX41jR+nc+fOCgsL89U0NmfOHN81P263W926dbuIvQQAAG3FNzLrqvEnkBpjvvZTSRvXNFd/MTXnmjVrlrxer+928ODBC/YEAADatssadDwejyQ1GVEpLS31jb54PB5VV1errKzsgjVHjx5tsv1jx4751TR+nLKyMtXU1DQZ6anncrkUFRXldwMAAPa6rEEnMTFRHo9H69ev9y2rrq7Wpk2bNGDAAElSamqqOnTo4FdTXFysoqIiX03//v3l9Xr10Ucf+Wo+/PBDeb1ev5qioiK/byJet26dXC6XUlNTL+duAWhjamtrtXHjRi1btkwbN270m9EJoH1p9Scjnzx5Ul988YXv971796qwsFDR0dG69tprlZWVpdmzZ6tHjx7q0aOHZs+erU6dOikjI0OS5Ha7NXnyZM2YMUNdunRRdHS0Zs6cqZSUFN1xxx2SpN69e2vkyJGaMmWKXn75ZUnSAw88oPT0dN14442SpOHDh+umm25SZmam5s2bp6+++kozZ87UlClTGKkB2rGcnBzNmDFD+/bt8y3r3r27XnzxRaaYA+1Ra6d0bdiwwUhqcrvvvvuMMc4U86efftp4PB7jcrnM7bffbnbs2OG3jcrKSjNt2jQTHR1twsPDTXp6ujlw4IBfzfHjx82kSZNMZGSkiYyMNJMmTTJlZWV+Nfv37zejR4824eHhJjo62kybNs2cOXOmxfvC9HLALitWrDBBQUFmzJgxJj8/31RUVJj8/HwzZswYExQUZFasWBHoFgFcBq05fgcZY0wAc1ZAlZeXy+12y+v1MgoEtHG1tbVKSkpSSkqKVq1apeDghjPzdXV1GjdunIqKirRnzx6+BgJo41pz/Oa7rgBYIS8vT/v27dNTTz3lF3IkKTg4WLNmzdLevXuVl5cXoA4BBALfXg7ACvUTE5KTk1VbW6u8vDzft5enpaUpOTnZrw5A+0DQAWCF+Ph4SdKiRYv08ssvN7kY+YEHHvCrA9A+cI0O1+gAVqitrVV8fLyOHTum0aNH66677lJ4eLgqKyu1du1arVmzRrGxsTpy5AjX6ABtXGuO34zoALBG/aei/+1vf9OaNWt8yzt27BiolgAEGBcjA7BCXl6eSktLm11XH4BKS0u5GBloZwg6AKxw+PBhSdLNN9/c5GtgYmNjdfPNN/vVAWgfOHUFwArHjh2TJH3yyScKDw/3W1daWqr9+/f71QFoHxjRAWCFLl26+P49dOhQ5efnq6KiQvn5+Ro6dGizdQDsR9ABYIVzr88JCgqSMcZ3q79Gp3EdAPtx6gqAFb766itJUs+ePbVjxw4NGDDAt6579+7q0aOH9uzZ46sD0D4QdABYof5rHz7//PMm68798MDGXw8BwG78Fw/ACoMHD76sdQDswIgOACuce6oqLCxM99xzj2699VZ9/PHHWrFihaqrq5vUAbAfIzoArPC73/3O9+/g4GAtW7ZMM2bM0LJly/y+8uHcOgD2I+gAsMKqVaskST/+8Y919dVX+627+uqrlZmZ6VcHoH0g6ACwQv0U8v3796u4uNhv3ZEjR3wfGHjuVHMA9iPoALDC3XffLUnatGmTunTpoldeeUXFxcV65ZVX1KVLF73//vt+dQDaB4IOACs89NBDvn/X1NRo165dysnJ0a5du1RTU9NsHQD7MesKgBX+8Ic/+P791VdfacGCBeety8rK+pa6AhBojOgAsMKXX37p+3fj63DO/f3cOgD2I+gAsEL37t0lSX369NHp06e1cOFCTZs2TQsXLtTp06eVkpLiVwegfeDUFQAr1AeZQ4cOKTQ01O/01NmzZ3X48GG/OgDtAyM6AKxw/PhxSc71OV27dtXSpUt15MgRLV26VF27dvV9mWd9HYD2gaADwArx8fGSpEmTJun48eN68MEHdc011+jBBx/U8ePHlZGR4VcHoH0g6ACwQlpamrp3767y8nJVVFT4XaNTUVGhiooKJSYmKi0tLdCtAvgWEXQAWCEkJEQvvviiVq9erYkTJ6pfv36aPXu2+vXrp4kTJ2r16tWaP3++3/deAbBfkDHGBLqJQCkvL5fb7ZbX61VUVFSg2wHavdOnT2v37t2XtI333ntPCxcu1JEjR3zLrrnmGmVlZWno0KGXtO1evXqpU6dOl7QNAJeuNcdvgg5BB7hibN++XampqYFu47wKCgp0yy23BLoNoN1rzfGb6eUArhi9evVSQUHBZdnWrl27dO+99+qNN95Q7969L8s2e/XqdVm2A+DbQ9ABcMXo1KnTZR8x6d27N6MwQDvGxcgAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrhQa6AQB22LNnjyoqKgLdhs+uXbv8fl4pIiMj1aNHj0C3AbQbBB0Al2zPnj3q2bNnoNto1r333hvoFpr4/PPPCTvAt4SgA+CS1Y/kvPHGG+rdu3eAu3FUVlZq37596t69u8LDwwPdjiRndOnee++9oka+ANsRdABcNr1799Ytt9wS6DZ8Bg4cGOgWAAQYFyMDAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWs64AXLKgs2d0sydY4Sc+l47w99P5hJ/4XDd7ghV09kygWwHaDYIOgEvW8eQBbX/wKun9B6X3A93Nlau3pO0PXqVdJw9IGhDodoB2gaAD4JKduepa3fLySb355pvq3atXoNu5Yu3avVuTJk3SH++6NtCtAO0GQQfAJTOhHfVJSZ0q/6mnlPCdQLdzxaosqdMnJXUyoR0D3QrQbnAyHQAAWIugAwAArEXQAQAA1mrzQWfx4sVKTExUx44dlZqaqry8vEC3BAAArhBtOui89dZbysrK0i9+8Qt98sknSktL06hRo3TgwIFAtwYAAK4AbXrW1YIFCzR58mT99Kc/lSS99NJLevfdd/X73/9ec+bMaVJfVVWlqqoq3+/l5eXfWq+AzU6fPi1J2r59+yVtp7KyUvv27bsMHX0zunfvrvDw8Iu+/65duy5jNwBaos0GnerqahUUFOjnP/+53/Lhw4dry5Ytzd5nzpw5evbZZ7+N9oB2Zffu3ZKkKVOmBLiTtiEyMjLQLQDtRpsNOv/4xz9UW1uruLg4v+VxcXEqKSlp9j6zZs3SE0884fu9vLxc3bp1+0b7BNqDcePGSZJ69eqlTp06XfR2bB/RkZyQ06NHj8vUEYCv02aDTr2goCC/340xTZbVc7lccrlc30ZbQLsSExPjO4V8qQYOHHhZtgMAUhu+GDkmJkYhISFNRm9KS0ubjPIAAID2qc0GnbCwMKWmpmr9+vV+y9evX68BA/iyPAAA0MZPXT3xxBPKzMzUrbfeqv79+2vp0qU6cOCAHnrooUC3BgAArgBtOuj88Ic/1PHjx/Xcc8+puLhYycnJWrt2ra677rpAtwYAAK4AQcYYE+gmAqW8vFxut1ter1dRUVGBbgcAALRAa47fbfYaHQAAgK9D0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWKtNfzLypar/rMTy8vIAdwIAAFqq/rjdks88btdBp6KiQpLUrVu3AHcCAABaq6KiQm63+4I17forIOrq6nTkyBFFRkYqKCgo0O0AuIzKy8vVrVs3HTx4kK94ASxjjFFFRYUSEhIUHHzhq3DaddABYC++yw6AxMXIAADAYgQdAABgLYIOACu5XC49/fTTcrlcgW4FQABxjQ4AALAWIzoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AFglffff19jxoxRQkKCgoKCtGrVqkC3BCCACDoArHLq1Cn17dtXixYtCnQrAK4A7frbywHYZ9SoURo1alSg2wBwhWBEBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtZh1BcAqJ0+e1BdffOH7fe/evSosLFR0dLSuvfbaAHYGIBCCjDEm0E0AwOWyceNGDRkypMny++67T6+99tq33xCAgCLoAAAAa3GNDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACs9f8BMkxH7tY1af4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_col = df_train.select_dtypes(include = ['float', 'int'])\n",
    "for col in num_col:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df_train[col])\n",
    "    plt.title('Boxplot of {}'.format(col), color = 'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a8a73",
   "metadata": {},
   "source": [
    "#### Finding the number of outliers in each numerical columns of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f9d004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outliers in the column ApplicantIncome  is 50\n",
      "The outliers in the column CoapplicantIncome  is 18\n",
      "The outliers in the column LoanAmount  is 41\n",
      "The outliers in the column Loan_Amount_Term  is 88\n",
      "The outliers in the column Credit_History  is 89\n"
     ]
    }
   ],
   "source": [
    "for col in num_col:\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - (1.5 * IQR)\n",
    "    upp = Q3 + (1.5 * IQR)\n",
    "    outliers = []\n",
    "    for x in df_train[col]:\n",
    "        if(x > upp) or (x < low):\n",
    "            outliers.append(x)\n",
    "    print('The outliers in the column', col, ' is', len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d295e",
   "metadata": {},
   "source": [
    "###### <font color = violet> For the record, we are not removing the outliers from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dda1aa",
   "metadata": {},
   "source": [
    "## <font color = brown> Pre-processing of testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad9fd2",
   "metadata": {},
   "source": [
    "#### Loading the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "255c27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\loan_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fcfaf",
   "metadata": {},
   "source": [
    "#### Loading the head of the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8386343c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001015   Male     Yes          0      Graduate            No   \n",
       "1  LP001022   Male     Yes          1      Graduate            No   \n",
       "2  LP001031   Male     Yes          2      Graduate            No   \n",
       "3  LP001035   Male     Yes          2      Graduate            No   \n",
       "4  LP001051   Male      No          0  Not Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5720                  0       110.0             360.0   \n",
       "1             3076               1500       126.0             360.0   \n",
       "2             5000               1800       208.0             360.0   \n",
       "3             2340               2546       100.0             360.0   \n",
       "4             3276                  0        78.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area  \n",
       "0             1.0         Urban  \n",
       "1             1.0         Urban  \n",
       "2             1.0         Urban  \n",
       "3             NaN         Urban  \n",
       "4             1.0         Urban  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5e58c",
   "metadata": {},
   "source": [
    "#### Getting the shape of the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aefd1b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b5531",
   "metadata": {},
   "source": [
    "#### Getting the info of the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de9c4cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 367 entries, 0 to 366\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            367 non-null    object \n",
      " 1   Gender             356 non-null    object \n",
      " 2   Married            367 non-null    object \n",
      " 3   Dependents         357 non-null    object \n",
      " 4   Education          367 non-null    object \n",
      " 5   Self_Employed      344 non-null    object \n",
      " 6   ApplicantIncome    367 non-null    int64  \n",
      " 7   CoapplicantIncome  367 non-null    int64  \n",
      " 8   LoanAmount         362 non-null    float64\n",
      " 9   Loan_Amount_Term   361 non-null    float64\n",
      " 10  Credit_History     338 non-null    float64\n",
      " 11  Property_Area      367 non-null    object \n",
      "dtypes: float64(3), int64(2), object(7)\n",
      "memory usage: 34.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb88f5",
   "metadata": {},
   "source": [
    "#### Finding the null values in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b6029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               11\n",
       "Married               0\n",
       "Dependents           10\n",
       "Education             0\n",
       "Self_Employed        23\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            5\n",
       "Loan_Amount_Term      6\n",
       "Credit_History       29\n",
       "Property_Area         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad2c7f",
   "metadata": {},
   "source": [
    "###### <font color = violet> There are null values in 6 columns in the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80085017",
   "metadata": {},
   "source": [
    "#### Displaying the distribution of float-datatype columns that contain null values in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49f861bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGxCAYAAABIjE2TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxuUlEQVR4nO3de3RU5b3G8WfMZRJiMpIgM8wiXLRIkXBRUCRqAwTiwgAqelCxFpfYogI1XLRQjhJsmwAqYk3VoggoAraWIBWLBEEoBZWLyKUu1GMIoOTEYpwEiAkk7/nDk70cEpSEiXkTvp+19lrOu9/97t9+MzqP+zLjMsYYAQAAWOS8xi4AAADgVAQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQ0OwsXLpTL5XKWqKgo+Xw+9e/fX9nZ2SoqKqqxTWZmplwuV532c/z4cWVmZuqdd96p03a17atDhw4aMmRIncb5IUuWLNHcuXNrXedyuZSZmRnS/YXa22+/rd69eysmJkYul0srVqyotd/+/fvlcrn0+OOP/7gF1sPKlSvlcrmUkJCg8vLyxi4n5N58803r31doOggoaLYWLFigLVu2KC8vT3/605/Us2dPzZo1S126dNHatWuD+t5zzz3asmVLncY/fvy4ZsyYUeeAUp991cf3BZQtW7bonnvuafAa6ssYoxEjRigiIkIrV67Uli1blJKS0thlnbX58+dLkr766qvTBq6m7M0339SMGTMauww0E+GNXQDQUJKSktS7d2/n9c0336wJEybommuu0fDhw/XJJ5/I6/VKktq2bau2bds2aD3Hjx9XixYtfpR9/ZCrrrqqUff/Q7744gt99dVXuummm5SamtrY5YREYWGh3nzzTQ0YMECbN2/W/PnzdeuttzZ2WYC1OIOCc0q7du30xBNPqLS0VH/+85+d9touu6xbt079+vVTQkKCoqOj1a5dO9188806fvy49u/frwsvvFCSNGPGDOdy0l133RU03o4dO3TLLbeoZcuWuvjii0+7r2q5ubnq3r27oqKidNFFF+mPf/xj0Prqy1f79+8Pan/nnXfkcrmcszn9+vXTqlWrVFBQEHS5q1ptl3j27NmjG264QS1btlRUVJR69uypRYsW1bqfpUuXatq0afL7/YqLi9PAgQO1b9++00/8d2zatEmpqamKjY1VixYtlJycrFWrVjnrMzMznQD3m9/8Ri6XSx06dDijsb/PgQMH9POf/1ytW7eW2+1Wly5d9MQTT6iqqiqo34wZM9SnTx/Fx8crLi5Ol19+uebPn69Tf1e1+rLc6tWrdfnllys6Olo//elP9eKLL9a6/0WLFunkyZOaMGGChg8frrffflsFBQU1+rlcLo0bN04LFixQ586dFR0drd69e+vdd9+VMUaPPfaYOnbsqPPPP18DBgzQp59+WmOMF198UT169FBUVJTi4+N100036aOPPgrq069fP/Xr16/GtnfddVfQfH/3EtqcOXOcffft21fvvvtu0HZ/+tOfnGOoXk59rwJnioCCc87111+vsLAwbdy48bR99u/fr/T0dEVGRurFF1/U6tWrNXPmTMXExKiiokJt2rTR6tWrJUmjR4/Wli1btGXLFj388MNB4wwfPlw/+clP9Ne//lXPPffc99a1c+dOZWRkaMKECcrNzVVycrIeeOCBet1b8cwzz+jqq6+Wz+dzavu+y0r79u1TcnKy9u7dqz/+8Y9avny5Lr30Ut11112aPXt2jf6//e1vVVBQoBdeeEHz5s3TJ598oqFDh6qysvJ769qwYYMGDBigQCCg+fPna+nSpYqNjdXQoUP16quvSvr2Etjy5cslSePHj9eWLVuUm5tb5zn4ri+//FLJyclas2aNfve732nlypUaOHCgJk+erHHjxgX13b9/v8aMGaO//OUvWr58uYYPH67x48frd7/7XY1xP/zwQ02aNEkTJkzQ66+/ru7du2v06NG1vrdefPFFtWnTRoMHD9bdd9+tqqoqLVy4sNZ633jjDb3wwguaOXOmli5dqtLSUqWnp2vSpEn617/+pZycHM2bN0///ve/dfPNNweFp+zsbI0ePVpdu3bV8uXL9dRTT2nXrl3q27evPvnkk3rP4Z/+9Cfl5eVp7ty5euWVV3Ts2DFdf/31CgQCkqSHH35Yt9xyiyQFvefatGlT733iHGeAZmbBggVGktm6detp+3i9XtOlSxfn9fTp0813/3V47bXXjCSzc+fO047x5ZdfGklm+vTpNdZVj/fII4+cdt13tW/f3rhcrhr7GzRokImLizPHjh0LOrb8/PygfuvXrzeSzPr165229PR00759+1prP7Xu2267zbjdbnPgwIGgfoMHDzYtWrQwX3/9ddB+rr/++qB+f/nLX4wks2XLllr3V+2qq64yrVu3NqWlpU7byZMnTVJSkmnbtq2pqqoyxhiTn59vJJnHHnvse8c7075Tpkwxksx7770X1H7fffcZl8tl9u3bV+t2lZWV5sSJE+bRRx81CQkJTn3GfPs3i4qKMgUFBU5bWVmZiY+PN2PGjAkaZ+PGjUaSmTJlijHGmKqqKtOxY0fTvn37oDGN+fZv4/P5zNGjR522FStWGEmmZ8+eQf3nzp1rJJldu3YZY4wpLi420dHRNf4+Bw4cMG6324wcOdJpS0lJMSkpKTWOedSoUUHvm+r57datmzl58qTT/v777xtJZunSpU7b2LFja7y3gfriDArOSeaU0/Wn6tmzpyIjI/WrX/1KixYt0meffVav/dx8881n3Ldr167q0aNHUNvIkSNVUlKiHTt21Gv/Z2rdunVKTU1VYmJiUPtdd92l48eP1zj7MmzYsKDX3bt3l6RaL1lUO3bsmN577z3dcsstOv/88532sLAw3XnnnTp06NAZXyaqq3Xr1unSSy/VlVdeGdR+1113yRijdevWBfUdOHCgPB6PwsLCFBERoUceeURHjhyp8QRYz5491a5dO+d1VFSULrnkkhrzUH1z7N133y1JzuXAgoICvf322zXq7d+/v2JiYpzXXbp0kSQNHjw46FJddXv1/rZs2aKysjLnUmO1xMREDRgwoNZ9nan09HSFhYU5r8/kbw6cDQIKzjnHjh3TkSNH5Pf7T9vn4osv1tq1a9W6dWuNHTtWF198sS6++GI99dRTddpXXU5v+3y+07YdOXKkTvutqyNHjtRaa/Ucnbr/hISEoNdut1uSVFZWdtp9FBcXyxhTp/2Eypke3/vvv6+0tDRJ0vPPP69//etf2rp1q6ZNmyap5vGdOg/St3Px3X6lpaX661//qiuvvFIXXnihvv76a3399de66aab5HK5nPDyXfHx8UGvIyMjv7f9m2++CTqO0x3r2cxvff7mwNngKR6cc1atWqXKyspabxD8rmuvvVbXXnutKisrtW3bNj399NPKyMiQ1+vVbbfddkb7qst3qxQWFp62rfrDISoqSpJqfIfGf/7znzPeT20SEhJ0+PDhGu1ffPGFJKlVq1ZnNb4ktWzZUuedd16D76c2Z3p8y5YtU0REhN544w1nriWd1SPBS5cu1fHjx/X++++rZcuWNdbn5uaquLi41nV1Vf0+Od2xfnd+o6KinPtHvuts30tAqHAGBeeUAwcOaPLkyfJ4PBozZswZbRMWFqY+ffo4TyhUX24J9f9B7t27Vx9++GFQ25IlSxQbG6vLL79ckpynK3bt2hXUb+XKlTXGO/X/5L9Pamqq1q1b53xgV3vppZfUokWLkDyWHBMToz59+mj58uVBdVVVVWnx4sVq27atLrnkkrPeT21SU1P173//u8alspdeekkul0v9+/eX9G2gDA8PD7qUUVZWppdffrne+54/f75iY2P19ttva/369UHLY489pvLycr3yyiv1Hv+7+vbtq+joaC1evDio/dChQ85lvGodOnTQxx9/HBR2jxw5os2bN9d7/5xVQShxBgXN1p49e3Ty5EmdPHlSRUVF+uc//6kFCxYoLCxMubm5zmPCtXnuuee0bt06paenq127dvrmm2+cx0cHDhwoSYqNjVX79u31+uuvKzU1VfHx8WrVqlW9H4n1+/0aNmyYMjMz1aZNGy1evFh5eXmaNWuWWrRoIUm64oor1LlzZ02ePFknT55Uy5YtlZubq02bNtUYr1u3blq+fLmeffZZ9erVS+edd17Q98J81/Tp0/XGG2+of//+euSRRxQfH69XXnlFq1at0uzZs+XxeOp1TKfKzs7WoEGD1L9/f02ePFmRkZF65plntGfPHi1durTO3+b7Xbt379Zrr71Wo/2KK67QhAkT9NJLLyk9PV2PPvqo2rdvr1WrVumZZ57Rfffd5wSj9PR0zZkzRyNHjtSvfvUrHTlyRI8//rjzwVtXe/bs0fvvv6/77rtPAwYMqLH+6quv1hNPPKH58+fXeJqoPi644AI9/PDD+u1vf6tf/OIXuv3223XkyBHNmDFDUVFRmj59utP3zjvv1J///Gf9/Oc/1y9/+UsdOXJEs2fPVlxcXL33361bN0nSrFmzNHjwYIWFhal79+7OpSigThr5Jl0g5KqfdKleIiMjTevWrU1KSorJysoyRUVFNbY59cmaLVu2mJtuusm0b9/euN1uk5CQYFJSUszKlSuDtlu7dq257LLLjNvtNpLMqFGjgsb78ssvf3Bfxnz7REh6erp57bXXTNeuXU1kZKTp0KGDmTNnTo3tP/74Y5OWlmbi4uLMhRdeaMaPH29WrVpV4ymer776ytxyyy3mggsuMC6XK2ifquXpo927d5uhQ4caj8djIiMjTY8ePcyCBQuC+lQ/xfPXv/41qL36SY9T+9fmn//8pxkwYICJiYkx0dHR5qqrrjJ///vfax2vLk/xnG6prqmgoMCMHDnSJCQkmIiICNO5c2fz2GOPmcrKyqDxXnzxRdO5c2fjdrvNRRddZLKzs838+fNrPD1V/Tc71XefjsnIyPjBp8GqnzDavn27Mebbv83YsWPPaD5O9/d44YUXTPfu3U1kZKTxeDzmhhtuMHv37q2x70WLFpkuXbqYqKgoc+mll5pXX331tE/x1Pa3OPV9VF5ebu655x5z4YUXOu+5U584A86Uy5gfeJwBAADgR8Y9KAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1mmSX9RWVVWlL774QrGxsWf1xU4AAODHY4xRaWmp/H6/zjvv+8+RNMmA8sUXX9T41VUAANA0HDx4UG3btv3ePk0yoMTGxkr69gDP5muZAQDAj6ekpESJiYnO5/j3aZIBpfqyTlxcHAEFAIAm5kxuz+AmWQAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTp0DysaNGzV06FD5/X65XC6tWLGiRp+PPvpIw4YNk8fjUWxsrK666iodOHDAWV9eXq7x48erVatWiomJ0bBhw3To0KGzOhAAANB81DmgHDt2TD169FBOTk6t6//nf/5H11xzjX7605/qnXfe0YcffqiHH35YUVFRTp+MjAzl5uZq2bJl2rRpk44ePaohQ4aosrKy/kcCAACaDZcxxtR7Y5dLubm5uvHGG5222267TREREXr55Zdr3SYQCOjCCy/Uyy+/rFtvvVWS9MUXXygxMVFvvvmmrrvuuh/cb0lJiTwejwKBAD8WCABAE1GXz++Q3oNSVVWlVatW6ZJLLtF1112n1q1bq0+fPkGXgbZv364TJ04oLS3NafP7/UpKStLmzZtrHbe8vFwlJSVBCwAAaL7CQzlYUVGRjh49qpkzZ+r3v/+9Zs2apdWrV2v48OFav369UlJSVFhYqMjISLVs2TJoW6/Xq8LCwlrHzc7O1owZM0JZarPTYcqqxi6hzvbPTG/sEgAAlgr5GRRJuuGGGzRhwgT17NlTU6ZM0ZAhQ/Tcc89977bGGLlcrlrXTZ06VYFAwFkOHjwYyrIBAIBlQhpQWrVqpfDwcF166aVB7V26dHGe4vH5fKqoqFBxcXFQn6KiInm93lrHdbvdiouLC1oAAEDzFdKAEhkZqSuuuEL79u0Lav/444/Vvn17SVKvXr0UERGhvLw8Z/3hw4e1Z88eJScnh7IcAADQRNX5HpSjR4/q008/dV7n5+dr586dio+PV7t27fTggw/q1ltv1c9+9jP1799fq1ev1t///ne98847kiSPx6PRo0dr0qRJSkhIUHx8vCZPnqxu3bpp4MCBITswAADQdNU5oGzbtk39+/d3Xk+cOFGSNGrUKC1cuFA33XSTnnvuOWVnZ+vXv/61OnfurL/97W+65pprnG2efPJJhYeHa8SIESorK1NqaqoWLlyosLCwEBwSAABo6s7qe1AaC9+DUhNP8QAAbNdo34MCAAAQCgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6dQ4oGzdu1NChQ+X3++VyubRixYrT9h0zZoxcLpfmzp0b1F5eXq7x48erVatWiomJ0bBhw3To0KG6lgIAAJqpOgeUY8eOqUePHsrJyfnefitWrNB7770nv99fY11GRoZyc3O1bNkybdq0SUePHtWQIUNUWVlZ13IAAEAzFF7XDQYPHqzBgwd/b5/PP/9c48aN01tvvaX09PSgdYFAQPPnz9fLL7+sgQMHSpIWL16sxMRErV27Vtddd11dSwIAAM1MyO9Bqaqq0p133qkHH3xQXbt2rbF++/btOnHihNLS0pw2v9+vpKQkbd68udYxy8vLVVJSErQAAIDmK+QBZdasWQoPD9evf/3rWtcXFhYqMjJSLVu2DGr3er0qLCysdZvs7Gx5PB5nSUxMDHXZAADAIiENKNu3b9dTTz2lhQsXyuVy1WlbY8xpt5k6daoCgYCzHDx4MBTlAgAAS4U0oPzzn/9UUVGR2rVrp/DwcIWHh6ugoECTJk1Shw4dJEk+n08VFRUqLi4O2raoqEher7fWcd1ut+Li4oIWAADQfIU0oNx5553atWuXdu7c6Sx+v18PPvig3nrrLUlSr169FBERoby8PGe7w4cPa8+ePUpOTg5lOQAAoImq81M8R48e1aeffuq8zs/P186dOxUfH6927dopISEhqH9ERIR8Pp86d+4sSfJ4PBo9erQmTZqkhIQExcfHa/LkyerWrZvzVA8AADi31TmgbNu2Tf3793deT5w4UZI0atQoLVy48IzGePLJJxUeHq4RI0aorKxMqampWrhwocLCwupaDgAAaIZcxhjT2EXUVUlJiTwejwKBAPej/L8OU1Y1dgl1tn9m+g93AgA0G3X5/Oa3eAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdeocUDZu3KihQ4fK7/fL5XJpxYoVzroTJ07oN7/5jbp166aYmBj5/X794he/0BdffBE0Rnl5ucaPH69WrVopJiZGw4YN06FDh876YAAAQPNQ54By7Ngx9ejRQzk5OTXWHT9+XDt27NDDDz+sHTt2aPny5fr44481bNiwoH4ZGRnKzc3VsmXLtGnTJh09elRDhgxRZWVl/Y8EAAA0G+F13WDw4MEaPHhwres8Ho/y8vKC2p5++mldeeWVOnDggNq1a6dAIKD58+fr5Zdf1sCBAyVJixcvVmJiotauXavrrruuHocBAACakwa/ByUQCMjlcumCCy6QJG3fvl0nTpxQWlqa08fv9yspKUmbN2+udYzy8nKVlJQELQAAoPlq0IDyzTffaMqUKRo5cqTi4uIkSYWFhYqMjFTLli2D+nq9XhUWFtY6TnZ2tjwej7MkJiY2ZNkAAKCRNVhAOXHihG677TZVVVXpmWee+cH+xhi5XK5a102dOlWBQMBZDh48GOpyAQCARRokoJw4cUIjRoxQfn6+8vLynLMnkuTz+VRRUaHi4uKgbYqKiuT1emsdz+12Ky4uLmgBAADNV8gDSnU4+eSTT7R27VolJCQEre/Vq5ciIiKCbqY9fPiw9uzZo+Tk5FCXAwAAmqA6P8Vz9OhRffrpp87r/Px87dy5U/Hx8fL7/brlllu0Y8cOvfHGG6qsrHTuK4mPj1dkZKQ8Ho9Gjx6tSZMmKSEhQfHx8Zo8ebK6devmPNUDAADObXUOKNu2bVP//v2d1xMnTpQkjRo1SpmZmVq5cqUkqWfPnkHbrV+/Xv369ZMkPfnkkwoPD9eIESNUVlam1NRULVy4UGFhYfU8DAAA0Jy4jDGmsYuoq5KSEnk8HgUCAe5H+X8dpqxq7BLqbP/M9MYuAQDwI6rL5ze/xQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArFPngLJx40YNHTpUfr9fLpdLK1asCFpvjFFmZqb8fr+io6PVr18/7d27N6hPeXm5xo8fr1atWikmJkbDhg3ToUOHzupAAABA81HngHLs2DH16NFDOTk5ta6fPXu25syZo5ycHG3dulU+n0+DBg1SaWmp0ycjI0O5ublatmyZNm3apKNHj2rIkCGqrKys/5EAAIBmI7yuGwwePFiDBw+udZ0xRnPnztW0adM0fPhwSdKiRYvk9Xq1ZMkSjRkzRoFAQPPnz9fLL7+sgQMHSpIWL16sxMRErV27Vtddd91ZHA4AAGgOQnoPSn5+vgoLC5WWlua0ud1upaSkaPPmzZKk7du368SJE0F9/H6/kpKSnD6nKi8vV0lJSdACAACarzqfQfk+hYWFkiSv1xvU7vV6VVBQ4PSJjIxUy5Yta/Sp3v5U2dnZmjFjRihLhQU6TFnV2CXU2f6Z6Y1dAgCcExrkKR6XyxX02hhTo+1U39dn6tSpCgQCznLw4MGQ1QoAAOwT0oDi8/kkqcaZkKKiIuesis/nU0VFhYqLi0/b51Rut1txcXFBCwAAaL5CGlA6duwon8+nvLw8p62iokIbNmxQcnKyJKlXr16KiIgI6nP48GHt2bPH6QMAAM5tdb4H5ejRo/r000+d1/n5+dq5c6fi4+PVrl07ZWRkKCsrS506dVKnTp2UlZWlFi1aaOTIkZIkj8ej0aNHa9KkSUpISFB8fLwmT56sbt26OU/1AACAc1udA8q2bdvUv39/5/XEiRMlSaNGjdLChQv10EMPqaysTPfff7+Ki4vVp08frVmzRrGxsc42Tz75pMLDwzVixAiVlZUpNTVVCxcuVFhYWAgOCQAANHUuY4xp7CLqqqSkRB6PR4FAgPtR/l9TfCKmKeIpHgCov7p8fvNbPAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOiEPKCdPntR///d/q2PHjoqOjtZFF12kRx99VFVVVU4fY4wyMzPl9/sVHR2tfv36ae/evaEuBQAANFEhDyizZs3Sc889p5ycHH300UeaPXu2HnvsMT399NNOn9mzZ2vOnDnKycnR1q1b5fP5NGjQIJWWloa6HAAA0ASFPKBs2bJFN9xwg9LT09WhQwfdcsstSktL07Zt2yR9e/Zk7ty5mjZtmoYPH66kpCQtWrRIx48f15IlS0JdDgAAaIJCHlCuueYavf322/r4448lSR9++KE2bdqk66+/XpKUn5+vwsJCpaWlOdu43W6lpKRo8+bNtY5ZXl6ukpKSoAUAADRf4aEe8De/+Y0CgYB++tOfKiwsTJWVlfrDH/6g22+/XZJUWFgoSfJ6vUHbeb1eFRQU1Dpmdna2ZsyYEepSAQCApUJ+BuXVV1/V4sWLtWTJEu3YsUOLFi3S448/rkWLFgX1c7lcQa+NMTXaqk2dOlWBQMBZDh48GOqyAQCARUJ+BuXBBx/UlClTdNttt0mSunXrpoKCAmVnZ2vUqFHy+XySvj2T0qZNG2e7oqKiGmdVqrndbrnd7lCXCgAALBXyMyjHjx/XeecFDxsWFuY8ZtyxY0f5fD7l5eU56ysqKrRhwwYlJyeHuhwAANAEhfwMytChQ/WHP/xB7dq1U9euXfXBBx9ozpw5uvvuuyV9e2knIyNDWVlZ6tSpkzp16qSsrCy1aNFCI0eODHU5AACgCQp5QHn66af18MMP6/7771dRUZH8fr/GjBmjRx55xOnz0EMPqaysTPfff7+Ki4vVp08frVmzRrGxsaEuBwAANEEuY4xp7CLqqqSkRB6PR4FAQHFxcY1djhU6TFnV2CWcE/bPTG/sEgCgyarL5ze/xQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArNMgAeXzzz/Xz3/+cyUkJKhFixbq2bOntm/f7qw3xigzM1N+v1/R0dHq16+f9u7d2xClAACAJijkAaW4uFhXX321IiIi9I9//EP//ve/9cQTT+iCCy5w+syePVtz5sxRTk6Otm7dKp/Pp0GDBqm0tDTU5QAAgCYoPNQDzpo1S4mJiVqwYIHT1qFDB+efjTGaO3eupk2bpuHDh0uSFi1aJK/XqyVLlmjMmDGhLgkAADQxIT+DsnLlSvXu3Vv/9V//pdatW+uyyy7T888/76zPz89XYWGh0tLSnDa3262UlBRt3ry51jHLy8tVUlIStAAAgOYr5AHls88+07PPPqtOnTrprbfe0r333qtf//rXeumllyRJhYWFkiSv1xu0ndfrddadKjs7Wx6Px1kSExNDXTYAALBIyANKVVWVLr/8cmVlZemyyy7TmDFj9Mtf/lLPPvtsUD+XyxX02hhTo63a1KlTFQgEnOXgwYOhLhsAAFgk5AGlTZs2uvTSS4PaunTpogMHDkiSfD6fJNU4W1JUVFTjrEo1t9utuLi4oAUAADRfIQ8oV199tfbt2xfU9vHHH6t9+/aSpI4dO8rn8ykvL89ZX1FRoQ0bNig5OTnU5QAAgCYo5E/xTJgwQcnJycrKytKIESP0/vvva968eZo3b56kby/tZGRkKCsrS506dVKnTp2UlZWlFi1aaOTIkaEuBwAANEEhDyhXXHGFcnNzNXXqVD366KPq2LGj5s6dqzvuuMPp89BDD6msrEz333+/iouL1adPH61Zs0axsbGhLgcAADRBLmOMaewi6qqkpEQej0eBQID7Uf5fhymrGruEc8L+memNXQIANFl1+fzmt3gAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrhDd2ATbqMGVVY5cAAMA5jTMoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1GjygZGdny+VyKSMjw2kzxigzM1N+v1/R0dHq16+f9u7d29ClAACAJqJBA8rWrVs1b948de/ePah99uzZmjNnjnJycrR161b5fD4NGjRIpaWlDVkOAABoIhosoBw9elR33HGHnn/+ebVs2dJpN8Zo7ty5mjZtmoYPH66kpCQtWrRIx48f15IlSxqqHAAA0IQ0WEAZO3as0tPTNXDgwKD2/Px8FRYWKi0tzWlzu91KSUnR5s2bax2rvLxcJSUlQQsAAGi+GuTHApctW6YdO3Zo69atNdYVFhZKkrxeb1C71+tVQUFBreNlZ2drxowZoS8UAABYKeRnUA4ePKgHHnhAixcvVlRU1Gn7uVyuoNfGmBpt1aZOnapAIOAsBw8eDGnNAADALiE/g7J9+3YVFRWpV69eTltlZaU2btyonJwc7du3T9K3Z1LatGnj9CkqKqpxVqWa2+2W2+0OdakAAMBSIT+Dkpqaqt27d2vnzp3O0rt3b91xxx3auXOnLrroIvl8PuXl5TnbVFRUaMOGDUpOTg51OQAAoAkK+RmU2NhYJSUlBbXFxMQoISHBac/IyFBWVpY6deqkTp06KSsrSy1atNDIkSNDXQ4AAGiCGuQm2R/y0EMPqaysTPfff7+Ki4vVp08frVmzRrGxsY1RDgAAsIzLGGMau4i6KikpkcfjUSAQUFxcXMjH7zBlVcjHRPOwf2Z6Y5cAAE1WXT6/G+UMCtBUNcXwSqgC0BTxY4EAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHVCHlCys7N1xRVXKDY2Vq1bt9aNN96offv2BfUxxigzM1N+v1/R0dHq16+f9u7dG+pSAABAExXygLJhwwaNHTtW7777rvLy8nTy5EmlpaXp2LFjTp/Zs2drzpw5ysnJ0datW+Xz+TRo0CCVlpaGuhwAANAEhYd6wNWrVwe9XrBggVq3bq3t27frZz/7mYwxmjt3rqZNm6bhw4dLkhYtWiSv16slS5ZozJgxoS4JAAA0MQ1+D0ogEJAkxcfHS5Ly8/NVWFiotLQ0p4/b7VZKSoo2b95c6xjl5eUqKSkJWgAAQPPVoAHFGKOJEyfqmmuuUVJSkiSpsLBQkuT1eoP6er1eZ92psrOz5fF4nCUxMbEhywYAAI2sQQPKuHHjtGvXLi1durTGOpfLFfTaGFOjrdrUqVMVCASc5eDBgw1SLwAAsEPI70GpNn78eK1cuVIbN25U27ZtnXafzyfp2zMpbdq0cdqLiopqnFWp5na75Xa7G6pUAABgmZCfQTHGaNy4cVq+fLnWrVunjh07Bq3v2LGjfD6f8vLynLaKigpt2LBBycnJoS4HAAA0QSE/gzJ27FgtWbJEr7/+umJjY537Sjwej6Kjo+VyuZSRkaGsrCx16tRJnTp1UlZWllq0aKGRI0eGuhwAANAEhTygPPvss5Kkfv36BbUvWLBAd911lyTpoYceUllZme6//34VFxerT58+WrNmjWJjY0NdDgAAaIJCHlCMMT/Yx+VyKTMzU5mZmaHePQAAaAb4LR4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsE97YBQBoWB2mrGrsEups/8z0xi4BQCPjDAoAALAOAQUAAFiHgAIAAKzDPSgArMN9MwA4gwIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWKdRv6jtmWee0WOPPabDhw+ra9eumjt3rq699trGLAkA6qUpfrmcxBfMwV6Ndgbl1VdfVUZGhqZNm6YPPvhA1157rQYPHqwDBw40VkkAAMASLmOMaYwd9+nTR5dffrmeffZZp61Lly668cYblZ2d/b3blpSUyOPxKBAIKC4uLuS1NdX/EwIAIFQa4uxaXT6/G+UST0VFhbZv364pU6YEtaelpWnz5s01+peXl6u8vNx5HQgEJH17oA2hqvx4g4wLAEBT0RCfsdVjnsm5kUYJKP/5z39UWVkpr9cb1O71elVYWFijf3Z2tmbMmFGjPTExscFqBADgXOaZ23Bjl5aWyuPxfG+fRr1J1uVyBb02xtRok6SpU6dq4sSJzuuqqip99dVXSkhIqLU/6q6kpESJiYk6ePBgg1w2O1cxrw2HuW0YzGvDYW6//ZwvLS2V3+//wb6NElBatWqlsLCwGmdLioqKapxVkSS32y232x3UdsEFFzRkieesuLi4c/ZfnIbEvDYc5rZhMK8N51yf2x86c1KtUZ7iiYyMVK9evZSXlxfUnpeXp+Tk5MYoCQAAWKTRLvFMnDhRd955p3r37q2+fftq3rx5OnDggO69997GKgkAAFii0QLKrbfeqiNHjujRRx/V4cOHlZSUpDfffFPt27dvrJLOaW63W9OnT69xKQ1nh3ltOMxtw2BeGw5zWzeN9j0oAAAAp8Nv8QAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BpRnbuHGjhg4dKr/fL5fLpRUrVgStN8YoMzNTfr9f0dHR6tevn/bu3RvUp7y8XOPHj1erVq0UExOjYcOG6dChQz/iUdgnOztbV1xxhWJjY9W6dWvdeOON2rdvX1Af5rZ+nn32WXXv3t35ps2+ffvqH//4h7OeeQ2N7OxsuVwuZWRkOG3Mbd1lZmbK5XIFLT6fz1nPnJ4dAkozduzYMfXo0UM5OTm1rp89e7bmzJmjnJwcbd26VT6fT4MGDVJpaanTJyMjQ7m5uVq2bJk2bdqko0ePasiQIaqsrPyxDsM6GzZs0NixY/Xuu+8qLy9PJ0+eVFpamo4dO+b0YW7rp23btpo5c6a2bdumbdu2acCAAbrhhhuc/6gzr2dv69atmjdvnrp37x7UztzWT9euXXX48GFn2b17t7OOOT1LBucESSY3N9d5XVVVZXw+n5k5c6bT9s033xiPx2Oee+45Y4wxX3/9tYmIiDDLli1z+nz++efmvPPOM6tXr/7RarddUVGRkWQ2bNhgjGFuQ61ly5bmhRdeYF5DoLS01HTq1Mnk5eWZlJQU88ADDxhjeM/W1/Tp002PHj1qXcecnj3OoJyj8vPzVVhYqLS0NKfN7XYrJSVFmzdvliRt375dJ06cCOrj9/uVlJTk9IEUCAQkSfHx8ZKY21CprKzUsmXLdOzYMfXt25d5DYGxY8cqPT1dAwcODGpnbuvvk08+kd/vV8eOHXXbbbfps88+k8SchkKjfdU9Glf1L0mf+uvRXq9XBQUFTp/IyEi1bNmyRp9Tf4n6XGWM0cSJE3XNNdcoKSlJEnN7tnbv3q2+ffvqm2++0fnnn6/c3Fxdeumlzn+wmdf6WbZsmXbs2KGtW7fWWMd7tn769Omjl156SZdccon+93//V7///e+VnJysvXv3MqchQEA5x7lcrqDXxpgabac6kz7ninHjxmnXrl3atGlTjXXMbf107txZO3fu1Ndff62//e1vGjVqlDZs2OCsZ17r7uDBg3rggQe0Zs0aRUVFnbYfc1s3gwcPdv65W7du6tu3ry6++GItWrRIV111lSTm9GxwieccVX2n+akpvaioyEn8Pp9PFRUVKi4uPm2fc9n48eO1cuVKrV+/Xm3btnXamduzExkZqZ/85Cfq3bu3srOz1aNHDz311FPM61nYvn27ioqK1KtXL4WHhys8PFwbNmzQH//4R4WHhztzw9yenZiYGHXr1k2ffPIJ79cQIKCcozp27Cifz6e8vDynraKiQhs2bFBycrIkqVevXoqIiAjqc/jwYe3Zs8fpcy4yxmjcuHFavny51q1bp44dOwatZ25Dyxij8vJy5vUspKamavfu3dq5c6ez9O7dW3fccYd27typiy66iLkNgfLycn300Udq06YN79dQaJRbc/GjKC0tNR988IH54IMPjCQzZ84c88EHH5iCggJjjDEzZ840Ho/HLF++3Ozevdvcfvvtpk2bNqakpMQZ49577zVt27Y1a9euNTt27DADBgwwPXr0MCdPnmysw2p09913n/F4POadd94xhw8fdpbjx487fZjb+pk6darZuHGjyc/PN7t27TK//e1vzXnnnWfWrFljjGFeQ+m7T/EYw9zWx6RJk8w777xjPvvsM/Puu++aIUOGmNjYWLN//35jDHN6tggozdj69euNpBrLqFGjjDHfPgY3ffp04/P5jNvtNj/72c/M7t27g8YoKysz48aNM/Hx8SY6OtoMGTLEHDhwoBGOxh61zakks2DBAqcPc1s/d999t2nfvr2JjIw0F154oUlNTXXCiTHMayidGlCY27q79dZbTZs2bUxERITx+/1m+PDhZu/evc565vTsuIwxpnHO3QAAANSOe1AAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ3/A+m1cENdb7IjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    plt.hist(df_test[i])\n",
    "    plt.title('Distribution of {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ac9af",
   "metadata": {},
   "source": [
    "###### <font color = violet> We can see that all the three float-datatype columns that contain null values of the testing dataset have about skewed distribution. So we can fill the null values in these columns with their respective medians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136e811",
   "metadata": {},
   "source": [
    "#### Filling the null values of the float-datatype columns of the testing dataset by their respective medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    df_test[j].fillna(df_test[j].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f21fa",
   "metadata": {},
   "source": [
    "#### Filling the null values of the string-datatype columns of the testing dataset by their respective mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f98a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['Gender', 'Dependents', 'Self_Employed']:\n",
    "    df_test[k].fillna(df_test[k].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a50e5",
   "metadata": {},
   "source": [
    "#### Finding whether there is any more null values in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "325fe2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cbc73",
   "metadata": {},
   "source": [
    "#### Displaying the statistical summary of the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aa8c5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4805.599455</td>\n",
       "      <td>1569.577657</td>\n",
       "      <td>135.980926</td>\n",
       "      <td>342.822888</td>\n",
       "      <td>0.839237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4910.685399</td>\n",
       "      <td>2334.232099</td>\n",
       "      <td>60.959739</td>\n",
       "      <td>64.658402</td>\n",
       "      <td>0.367814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2864.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3786.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5060.000000</td>\n",
       "      <td>2430.500000</td>\n",
       "      <td>157.500000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72529.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       367.000000         367.000000  367.000000        367.000000   \n",
       "mean       4805.599455        1569.577657  135.980926        342.822888   \n",
       "std        4910.685399        2334.232099   60.959739         64.658402   \n",
       "min           0.000000           0.000000   28.000000          6.000000   \n",
       "25%        2864.000000           0.000000  101.000000        360.000000   \n",
       "50%        3786.000000        1025.000000  125.000000        360.000000   \n",
       "75%        5060.000000        2430.500000  157.500000        360.000000   \n",
       "max       72529.000000       24000.000000  550.000000        480.000000   \n",
       "\n",
       "       Credit_History  \n",
       "count      367.000000  \n",
       "mean         0.839237  \n",
       "std          0.367814  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e21c05",
   "metadata": {},
   "source": [
    "#### Finding outliers in the numerical columns of the testing dataset using boxplot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dc53164",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGxCAYAAABIjE2TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwLUlEQVR4nO3df3RV5Z3v8c/JCQlJTHL5mR8aSLoSCzWxltgLjU1JCsKg4OTGaMdUB1dtFyIwkxaKA6654r02GZUftgu1pbWiUsBpjLFGa8FRMJTYi6GMhqKG1cQBSRpqMQlwSCB57h97zgknCciB6H6SvF9rnRXOs5+zz/fsZLE/59nP3ttjjDECAACwSJjbBQAAAPRGQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAfqzcaPk8QQ/xo2T8vKkqiq3q+uRmirdeWforzt5Ulq1StqxY2DrkaTGRunGG6XRo53tVlJy7r6pqdLcuQNfw0D761+lyEjn87z9ttvVDLw//cn5e2hsdLsSIICAApzPU09JNTXS7t3Shg2S1yvNmye99JLblV2akyelBx74bALK978v/eEP0i9/6Wy7739/4N/j8/bss1Jnp/PvJ590t5bPwp/+5Pw9EFBgkXC3CwCslpkpXXttz/O/+ztp1ChpyxYnqKCvujrpf/5PqaDA7UoGzi9/KY0fL02c6Pzu166VoqLcrgoY0hhBAUIxcqQUESGNGBHc/re/SffcI11+ubP8C1+Q7rtP6uhwlp86JX3lK1J6utTa2vO65mYpMdE5dNTV5bTdead02WXS/v3SjBlSTIxzeGnxYmfk49P8139Jt9/u7FAjI6XJk6U1a6Tubmd5Y6OzPsn51uw/hPVph4o+bb07djjrOXhQ+u1ve9Z7qd/KT52SVqyQ0tKcbXv55dKiRdInnwT3e+45adYsKSnJCQ+TJ0v/8i/SiRPB/fzb9+BB6YYbnH+npEhLl/b8vs72hz84oeuOO6Tvfc/5/T3/fN9+eXlOoK2pkXJynBpSU51ROEl6+WVpyhQpOlrKypJefbXvOnbtcn7nsbFOv5wc53VnW7XK2a69+Q9Lnr29/YfQXn3Vee+oKGnSJCdwnf26W25x/p2f3/N727ix73sAnycDoK+nnjJGMuatt4w5fdqYzk5jDh0y5p/+yZiwMGNefbWnr89nzNVXGxMTY8zq1cZs22bMv/6rMeHhxtxwQ0+/Dz4wJjbWmMJC53lXlzHf/KYx48cbc+RIT7/5842JiDBmwgRjfvQjZ32rVjnrmzs3uM6JE53+fi0txlx+uTHjxhnz0586dS5e7HyWhQudPqdOOe2SMXfdZUxNjfM4ePDc2+NC1tva6qwnMdGY667rWe+pU+de78SJxtx447mXd3cbM3u289n/9V+dbbF6tbOtv/KV4HX/3/9rzLp1xrz8sjE7djh1pqUZk58fvE7/9p082VnXa68Z87//tzEejzEPPNC3hu99z/mc+/cb09ZmTHS0MXl5fftNn27MmDHGfPGLxjz5pDG/+53z+5Kc9WZlGbNlizGvvGLMtGnGREYa89FHPa/fscOYESOMyc425rnnjKmsNGbWLKeurVt7+t1/v7PO3vx/sw0Nwdv3iiuM+dKXjHnmGaemW25x+u3c6fRpaTGmtNRpe+yxnt9bS8u5fy/A54CAAvTH/59970dkpDGPPx7c96c/dZb9+78Htz/0kNO+bVtP23PPOW2PPursFMPCgpcb4+xAJWN+/OPg9h/9yGnftaunrXdA+Zd/cfr84Q/Br1240NnRvf++8/zoUaff/fdf0Oa44PX6azpf6Djbp/X1B6mHHw5u92/HDRv6f113txMsd+50+v3nf/Ys82/f3r+vG25wwsXZTpwwJi7OCRRnv97j6Rvopk931vv22z1tH39sjNdrTFRUcBjZt8/p+5Of9LRNm+aE1fb2nrYzZ4zJzHRCRne30xZqQBk50pgPP+xp8/mMGT3amAULetp+/WvntW+80Xe9gEs4xAOczzPPSHv2OI/f/laaP985vLB+fU+f1193DsMUFQW/1n/I5D/+o6ft1lulhQulH/5QevBBaeVK6frr+3/vb387+HlxsfPzjTfOXe/rr0tf+pIzB6R3LcY4yy/GZ7XeC3lf//uc7ZZbnG1+9rb985+dbZSY6ExmHjFCmj7dWXbgQPDrPZ6+c4iuvlr68MPgtn//d6mtTfrOd3ravvMd5zP7D92cLSlJys7ueT56tHNI7JprpOTknvbJk52f/vc7ccI5lFRU5Bxy8vN6nUNLhw9L77/f9/0uxDXXSBMm9DwfOVK68sq+nxWwDAEFOJ/Jk51Jstde60yQ/dnPnHkOy5f3zIH4+GNnp9h7XsD48VJ4uLP8bN/5jnT6tLPsn/6p//cND5fGjAluS0zseb9z+fhjZyfZm3/neL7Xns9ntd4Led/w8J45M34ej7M9/O97/LiUm+vs5B980JkPs2ePVFHhLPf5gl8fHe3sqM8WGenMdznbk086/f7u75zf9yefOEEmNdWZo+GfN+Q3enTfzxAR0bc9IsL56X+/Y8ec0PNZbOPef0eS81l7bxPAMgQUIFRXX+385/7BB87zMWOkv/zF2cGcraVFOnNGGju2p+3ECecb8ZVXOhMWv/vd/t/jzJm+O6Tm5p73O5cxY6Smpr7tR444P8+uJRSf1Xov5H3PnJGOHg1uN8bZHv73ff11p5Zf/tLZpt/4hhMqY2Mv/r0/+MCZtHrqlDMCMWpUz6OxUfroI+l3v7v49Z9t1CgpLOzCtrE/WPWe0PvXvw5MLYAlCChAqPbtc376v9XPmOF8g6+sDO73zDM9y/3uvts5G6aiwvl2/pvfSOvW9f8+v/pV8PPNm52feXnnrm3GDOeaFnv39q3F43HO0pCcb9DShX+LvtD1DjT/ttu0Kbj9+eedsOdf7h+98n8uv5/97OLf23+9k5//3DmsdvbjlVecQ0hnnw1zKWJipKlTnb+Ls38n3d3OZ7/iCifUSs7ojSS9807wOi7l2jyh/j0AnwOugwKcT12d8w1eckY0Kiqk7dul//W/nNNeJekf/1F67DFnfkpjo3MK6a5dUmmpcxrrzJlOv1/8wtnZPPWUdNVVzmPxYunee6Xrrgue3xER4ZzCe/y49NWvOheKe/BBac4c6etfP3e93/++ExpuvFH6P//HuW7Hyy9Ljz/uzH3x7+RiY51lL77o7ORHj3a+oft3fhe73ovR3CyVl/dtT0115ufMnu1so7Y2Zzu98450//3Oadt33OH0zclxRiHuvttZNmKEE/D+8z8vrqYzZ5zPO3nyuUe55s1zAubRo30PQV2MsjLn8+bnS8uWOX8Djz/u/A1u2dITwm64wfl93XWX87sID3cONx06dPHvnZnp/NywwfnbGDnS+fs+32gd8Flze5YuYKX+zuKJjzfmmmuMWbu276mzH39szN13G5OU5JwSO3GiMStW9PR75x3nTI6zz7gxxlmenW1Maqoxx445bfPnO6fRvvOOczprVJRz1sXChcYcPx78+t5n8RjjnLFRXOyc8jpihHNmyiOPOKc1n+2115xTdSMjnc/Xez29Xeh6Qz2Lp7+zpc6ux+cz5t57nb4jRjjbeOHCnu3lt3u3MV/7mnMa8Lhxxnz3u8bs3eus66mnevr5t29vZ58dU1nZc7bVufjPMFqzxnk+fboxV13V/2fsb3tIxixaFNxWXe2ceh4T4/zep00z5qWX+r72//0/Y3JynH6XX+7U/otf9H8WT3/vPX268zjbo486p2V7vX23GeACjzG9D5wDcNWddzojCsePu10JALiGOSgAAMA6BBQAAGAdDvEAAADrMIICAACsQ0ABAADWIaAAAADrDMoLtXV3d+vIkSOKjY2Vp/f9TwAAgJWMMWpvb1dycrLCws4/RjIoA8qRI0eUkpLidhkAAOAiHDp0SFdcccV5+wzKgBL73zcAO3TokOLi4lyuBgAAXIi2tjalpKQE9uPnMygDiv+wTlxcHAEFAIBB5kKmZzBJFgAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwzqC8UBuAoamrq0vV1dVqampSUlKScnNz5fV63S4LgAsYQQFghYqKCqWnpys/P1/FxcXKz89Xenq6Kioq3C4NgAsIKABcV1FRoaKiImVlZammpkbt7e2qqalRVlaWioqKCCnAMOQxxhi3iwhVW1ub4uPj1drayr14gEGuq6tL6enpysrKUmVlZdAt2Lu7u1VQUKC6ujrV19dzuAcY5ELZfzOCAsBV1dXVamxs1MqVK4PCiSSFhYVpxYoVamhoUHV1tUsVAnADAQWAq5qamiRJmZmZ/S73t/v7ARgeCCgAXJWUlCRJqqur63e5v93fD8DwQEAB4Krc3FylpqaqtLRU3d3dQcu6u7tVVlamtLQ05ebmulQhADcQUAC4yuv1as2aNaqqqlJBQUHQWTwFBQWqqqrS6tWrmSALDDNcqA2A6woLC1VeXq6lS5cqJycn0J6Wlqby8nIVFha6WB0AN3CaMQBrcCVZYGgLZf/NCAoAa3i9XuXl5bldBgALMAcFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOiEFlFWrVsnj8QQ9EhMTA8uNMVq1apWSk5MVFRWlvLw87d+/P2gdHR0dWrJkicaOHauYmBjddNNNOnz48MB8GgAAMCSEPIJy1VVXqampKfB49913A8sefvhhrV27VuvXr9eePXuUmJio66+/Xu3t7YE+JSUleuGFF7R161bt2rVLx48f19y5c9XV1TUwnwgAAAx64SG/IDw8aNTEzxijRx99VPfdd58KCwslSU8//bQSEhK0efNmLViwQK2trXryySf17LPPaubMmZKkTZs2KSUlRa+99ppmz559iR8HAAAMBSGPoNTX1ys5OVlpaWn6h3/4B/35z3+WJDU0NKi5uVmzZs0K9I2MjNT06dO1e/duSVJtba1Onz4d1Cc5OVmZmZmBPv3p6OhQW1tb0AMAAAxdIQWUqVOn6plnntHvfvc7/fznP1dzc7NycnL08ccfq7m5WZKUkJAQ9JqEhITAsubmZkVERGjUqFHn7NOfsrIyxcfHBx4pKSmhlA0AAAaZkALKnDlzdPPNNysrK0szZ87Uyy+/LMk5lOPn8XiCXmOM6dPW26f1WbFihVpbWwOPQ4cOhVI2AAAYZC7pNOOYmBhlZWWpvr4+MC+l90hIS0tLYFQlMTFRnZ2dOnbs2Dn79CcyMlJxcXFBDwAAMHRdUkDp6OjQgQMHlJSUpLS0NCUmJmr79u2B5Z2dndq5c6dycnIkSdnZ2RoxYkRQn6amJtXV1QX6AAAAhHQWz7JlyzRv3jxNmDBBLS0tevDBB9XW1qb58+fL4/GopKREpaWlysjIUEZGhkpLSxUdHa3i4mJJUnx8vO666y4tXbpUY8aM0ejRo7Vs2bLAISMAAAApxIBy+PBh3XbbbfrrX/+qcePGadq0aXrrrbc0ceJESdLy5cvl8/l0zz336NixY5o6daq2bdum2NjYwDrWrVun8PBw3XrrrfL5fJoxY4Y2btwor9c7sJ8MAAAMWh5jjHG7iFC1tbUpPj5era2tzEcBAGCQCGX/zb14AACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFgn3O0CAMCvq6tL1dXVampqUlJSknJzc+X1et0uC4ALGEEBYIWKigqlp6crPz9fxcXFys/PV3p6uioqKtwuDYALCCgAXFdRUaGioiJlZWWppqZG7e3tqqmpUVZWloqKiggpwDDkMcYYt4sIVVtbm+Lj49Xa2qq4uDi3ywFwCbq6upSenq6srCxVVlYqLKzne1N3d7cKCgpUV1en+vp6DvcAg1wo+29GUAC4qrq6Wo2NjVq5cmVQOJGksLAwrVixQg0NDaqurnapQgBuIKAAcFVTU5MkKTMzs9/l/nZ/PwDDAwEFgKuSkpIkSXV1df0u97f7+wEYHggoAFyVm5ur1NRUlZaWqru7O2hZd3e3ysrKlJaWptzcXJcqBOAGAgoAV3m9Xq1Zs0ZVVVUqKCgIOounoKBAVVVVWr16NRNkgWGGC7UBcF1hYaHKy8u1dOlS5eTkBNrT0tJUXl6uwsJCF6sD4AZOMwZgDa4kCwxtoey/GUEBYA2v16u8vDy3ywBgAeagAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDrhbhcAAH5dXV2qrq5WU1OTkpKSlJubK6/X63ZZAFzACAoAK1RUVCg9PV35+fkqLi5Wfn6+0tPTVVFR4XZpAFxAQAHguoqKChUVFSkrK0s1NTVqb29XTU2NsrKyVFRUREgBhiGPMca4XUSo2traFB8fr9bWVsXFxbldDoBL0NXVpfT0dGVlZamyslJhYT3fm7q7u1VQUKC6ujrV19dzuAcY5ELZfzOCAsBV1dXVamxs1MqVK4PCiSSFhYVpxYoVamhoUHV1tUsVAnADAQWAq5qamiRJmZmZ/S73t/v7ARgeCCgAXJWUlCRJqqur63e5v93fD8DwQEAB4Krc3FylpqaqtLRU3d3dQcu6u7tVVlamtLQ05ebmulQhADcQUAC4yuv1as2aNaqqqlJBQUHQWTwFBQWqqqrS6tWrmSALDDOXFFDKysrk8XhUUlISaDPGaNWqVUpOTlZUVJTy8vK0f//+oNd1dHRoyZIlGjt2rGJiYnTTTTfp8OHDl1IKgEGssLBQ5eXlevfdd5WTk6O4uDjl5OSorq5O5eXlKiwsdLtEAJ+ziw4oe/bs0YYNG3T11VcHtT/88MNau3at1q9frz179igxMVHXX3+92tvbA31KSkr0wgsvaOvWrdq1a5eOHz+uuXPnqqur6+I/CYBBrbCwUAcPHtQbb7yhzZs364033lB9fT3hBBimLuo6KMePH9eUKVP0+OOP68EHH9Q111yjRx99VMYYJScnq6SkRPfee68kZ7QkISFBDz30kBYsWKDW1laNGzdOzz77rL71rW9Jko4cOaKUlBS98sormj179qe+P9dBAQBg8PnMr4OyaNEi3XjjjZo5c2ZQe0NDg5qbmzVr1qxAW2RkpKZPn67du3dLkmpra3X69OmgPsnJycrMzAz06a2jo0NtbW1BDwAAMHSFfLPArVu3au/evdqzZ0+fZc3NzZKkhISEoPaEhAR9+OGHgT4REREaNWpUnz7+1/dWVlamBx54INRSAQDAIBXSCMqhQ4f0z//8z9q0aZNGjhx5zn4ejyfouTGmT1tv5+uzYsUKtba2Bh6HDh0KpWwAg0RXV5d27NihLVu2aMeOHcxLA4axkAJKbW2tWlpalJ2drfDwcIWHh2vnzp36yU9+ovDw8MDISe+RkJaWlsCyxMREdXZ26tixY+fs01tkZKTi4uKCHgCGFu5mDOBsIQWUGTNm6N1339W+ffsCj2uvvVbf/va3tW/fPn3hC19QYmKitm/fHnhNZ2endu7cqZycHElSdna2RowYEdSnqalJdXV1gT4AhhfuZgygt0u+m3FeXl7gLB5Jeuihh1RWVqannnpKGRkZKi0t1Y4dO/T+++8rNjZWkrRw4UJVVVVp48aNGj16tJYtW6aPP/5YtbW1F3QxJs7iAYYO7mYMDB+h7L9DniT7aZYvXy6fz6d77rlHx44d09SpU7Vt27ZAOJGkdevWKTw8XLfeeqt8Pp9mzJihjRs38p8PMAz572a8ZcuWc97NOCcnR9XV1crLy3OnSACfu0seQXEDIyjA0LFlyxYVFxervb1dl112WZ/l7e3tiouL0+bNm3Xbbbe5UCGAgfKZXwcFAAYKdzMG0B8CCgBXcTdjAP0hoABwFXczBtCfAZ8kCwCh8t/NeOnSpUGXG0hLS+NuxsAwxSRZANbo6upSdXW1mpqalJSUpNzcXEZOgCHE1dOMAeBieb1eTiUGIIk5KAAAwEIEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdbhQGwBrcCVZAH6MoACwQkVFhdLT05Wfn6/i4mLl5+crPT1dFRUVbpcGwAUEFACuq6ioUFFRkbKysoLuZpyVlaWioiJCCjAMcbNAAK7q6upSenq6srKyVFlZqbCwnu9N3d3dKigoUF1dnerr6zncAwxyoey/GUEB4Krq6mo1NjZq5cqVQeFEksLCwrRixQo1NDSourrapQoBuIGAAsBVTU1NkqTMzMx+l/vb/f0ADA8EFACuSkpKkiTV1dX1u9zf7u8HYHggoABwVW5urlJTU1VaWqru7u6gZd3d3SorK1NaWppyc3NdqhCAGwgoAFzl9Xq1Zs0aVVVVqaCgIOgsnoKCAlVVVWn16tVMkAWGGS7UBsB1hYWFKi8v19KlS5WTkxNoT0tLU3l5uQoLC12sDoAbOM0YgDW4kiwwtIWy/2YEBYA1vF6v8vLy3C4DgAWYgwIAAKxDQAEAANYhoAAAAOswBwWANZgkC8CPERQAVqioqFB6erry8/NVXFys/Px8paencydjYJgioABwXUVFhYqKipSVlRV0obasrCwVFRURUoBhiOugAHBVV1eX0tPTlZWVpcrKyqA7Gnd3d6ugoEB1dXWqr6/ncA8wyIWy/2YEBYCrqqur1djYqJUrVwaFE0kKCwvTihUr1NDQoOrqapcqBOAGAgoAVzU1NUmSMjMz+13ub/f3AzA8EFAAuCopKUmSVFdX1+9yf7u/H4DhgYACwFW5ublKTU1VaWmpuru7g5Z1d3errKxMaWlpys3NdalCAG4goABwldfr1Zo1a1RVVaWCgoKgs3gKCgpUVVWl1atXM0EWGGa4UBsA1xUWFqq8vFxLly5VTk5OoD0tLU3l5eUqLCx0sToAbuA0YwDW4EqywNAWyv6bERQA1vB6vcrLy3O7DAAWYA4KAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAFgDZ/Pp8WLF2v27NlavHixfD6f2yUBcAl3MwZghYKCAr344ot92v/+7/9elZWVn39BAAZcKPvvkEZQnnjiCV199dWKi4tTXFycvva1r+m3v/1tYLkxRqtWrVJycrKioqKUl5en/fv3B62jo6NDS5Ys0dixYxUTE6ObbrpJhw8fDqUMAEOMP5xERESouLhYa9euVXFxsSIiIvTiiy+qoKDA7RIBfM5CGkF56aWX5PV6lZ6eLkl6+umn9cgjj+iPf/yjrrrqKj300EP60Y9+pI0bN+rKK6/Ugw8+qDfffFPvv/++YmNjJUkLFy7USy+9pI0bN2rMmDFaunSp/va3v6m2tlZer/eC6mAEBRg6fD6foqOjFR4erssvv1wffvhhYNnEiRP10Ucf6cyZMzp58qSioqJcrBTApQpp/20u0ahRo8wvfvEL093dbRITE82//du/BZadOnXKxMfHm5/+9KfGGGM++eQTM2LECLN169ZAn48++siEhYWZV1999ZzvcerUKdPa2hp4HDp0yEgyra2tl1o+AJctWrTISDKSzLx580xNTY1pb283NTU1Zt68eYFlixYtcrtUAJeotbX1gvffFz1JtqurS1u3btWJEyf0ta99TQ0NDWpubtasWbMCfSIjIzV9+nTt3r1bklRbW6vTp08H9UlOTlZmZmagT3/KysoUHx8feKSkpFxs2QAs88EHH0iSvvnNb6qyslLTpk3TZZddpmnTpqmyslL5+flB/QAMDyEHlHfffVeXXXaZIiMjdffdd+uFF17Ql770JTU3N0uSEhISgvonJCQEljU3NysiIkKjRo06Z5/+rFixQq2trYHHoUOHQi0bgKViYmIkSZdffrnCwoL/SwoLC1NycnJQPwDDQ8gB5Ytf/KL27dunt956SwsXLtT8+fP1pz/9KbDc4/EE9TfG9Gnr7dP6REZGBibm+h8Ahgb/BNjnnntOPp9PO3bs0JYtW7Rjxw75fD79+te/DuoHYHgID/UFERERgUmy1157rfbs2aMf//jHuvfeeyU5oyRJSUmB/i0tLYFRlcTERHV2durYsWNBoygtLS3Kycm5pA8CYHCaOHGiJKmzs1PR0dGf2g/A8HDJF2ozxqijo0NpaWlKTEzU9u3bA8s6Ozu1c+fOQPjIzs7WiBEjgvo0NTWprq6OgAIMU7m5uRo/fvx5+4wfP165ubmfU0UAbBDSCMrKlSs1Z84cpaSkqL29XVu3btWOHTv06quvyuPxqKSkRKWlpcrIyFBGRoZKS0sVHR2t4uJiSVJ8fLzuuusuLV26VGPGjNHo0aO1bNkyZWVlaebMmZ/JBwRgP/PfVzu44YYbFBUVFRhl9fl8euWVV1yuDoAbQgoof/nLX3THHXeoqalJ8fHxuvrqq/Xqq6/q+uuvlyQtX75cPp9P99xzj44dO6apU6dq27ZtgWugSNK6desUHh6uW2+9VT6fTzNmzNDGjRsv+BooAIaW6upqHT16VGVlZfrZz36mxsbGwLK0tDSVlpZq5cqVqq6uVl5enmt1Avh8cal7AK7asmWLiouL1d7erqioKFVXV6upqUlJSUnKzc3VyZMnFRcXp82bN+u2225zu1wAl+Azu9Q9AAw0/6T6urq6fpf728+efA9g6GMEBYCrurq6lJ6errFjx+ro0aN9LnU/btw4ffzxx6qvr+dQMDDIMYICYNDwer265ZZb9Pbbb+vUqVPasGGDjhw5og0bNujUqVN6++23VVRURDgBhhlGUAC46nwjKKmpqRo7diwjKMAQwQgKgEGjurpajY2Nuvnmm/u9onRhYaEaGhpUXV3tQnUA3EJAAeCqpqYmSc51lrKyslRTU6P29nbV1NQoKytL9913X1A/AMNDyJe6B4CB5L+K7HXXXafKysrADQP9dzOePn26du3a9alXmwUwtDCCAsBqg3CaHIABQEAB4KqWlhZJ0q5du1RQUBB0iKegoEC///3vg/oBGB4IKABc5b8AW1lZmd59913l5OQoLi5OOTk5qqurU2lpaVA/AMMDc1AAuCo3N1epqanavXu3PvjgA/3+978PXOr+uuuu080336y0tDTuZgwMM4ygAHCV1+vVmjVrVFVVpZtvvlmRkZGaO3euIiMjdfPNN6uqqkqrV6/mGijAMMMICgDXFRYWqry8XEuXLlVOTk6gPS0tTeXl5SosLHSxOgBu4EqyAKzh8/n0wx/+UPX19crIyNAjjzyiqKgot8sCMEC4kiyAQWf58uWKi4vTY489pm3btumxxx5TXFycli9f7nZpAFzAIR4Arlu+fLkeeeQRJSQk6I477tAXvvAF/fnPf9azzz6rRx55RJL08MMPu1wlgM8Th3gAuKqzs1MxMTGKiYlRXFycDh06FFiWkpKitrY2nThxQidOnFBERISLlQK4VBziATBoPP744zpz5oxaW1t19OjRoGVHjx5Va2urzpw5o8cff9ylCgG4gYACwFX19fWBf/e+m/HZz8/uB2DoI6AAcFV3d3fg3zNmzAi61P2MGTP67Qdg6GOSLABX+Y9DjxgxQs8//3xgnsm0adP0/PPP67LLLtPp06eZbwYMM4ygAHDVkSNHJEmnT5/WhAkTtGHDBh05ckQbNmzQhAkTdPr06aB+AIYHRlAAuGrChAmSnJsBHj16VAsWLAgsCw8PV1JSkpqamgL9AAwPBBQArvrmN7+p0tJSNTU16YYbblB6erpOnTqlkSNH6uDBg3rllVcC/QAMH1wHBYCrurq6lJycrJaWFo0cOVKnTp0KLIuKipLP59P48eN15MgRbhgIDHJcBwXAoOH1evXEE0/I4/H0e5qxx+PRE088QTgBhhkCCgDX+e9mnJCQENSekJDA3YyBYYpDPACs0dXVperqajU1NSkpKUm5ubmMnABDSCj7bybJArCG1+tVXl6e22UAsACHeAAAgHUYQQEwIE6ePKn33nvvktfj8/nU2Nio1NRURUVFDUBl0qRJkxQdHT0g6wLw+SCgABgQ7733nrKzs90uo1+1tbWaMmWK22UACAEBBcCAmDRpkmpray95PQcOHNDtt9+uTZs2afLkyQNQmVMbgMGFgAJgQERHRw/oKMXkyZMZ9QCGMSbJAgAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDohBZSysjJ99atfVWxsrMaPH6+CggK9//77QX2MMVq1apWSk5MVFRWlvLw87d+/P6hPR0eHlixZorFjxyomJkY33XSTDh8+fOmfBgAADAkhBZSdO3dq0aJFeuutt7R9+3adOXNGs2bN0okTJwJ9Hn74Ya1du1br16/Xnj17lJiYqOuvv17t7e2BPiUlJXrhhRe0detW7dq1S8ePH9fcuXPV1dU1cJ8MAAAMWh5jjLnYFx89elTjx4/Xzp079Y1vfEPGGCUnJ6ukpET33nuvJGe0JCEhQQ899JAWLFig1tZWjRs3Ts8++6y+9a1vSZKOHDmilJQUvfLKK5o9e/anvm9bW5vi4+PV2tqquLi4iy0fgIX27t2r7Oxs1dbWasqUKW6XA2AAhbL/vqQ5KK2trZKk0aNHS5IaGhrU3NysWbNmBfpERkZq+vTp2r17tySptrZWp0+fDuqTnJyszMzMQJ/eOjo61NbWFvQAAABD10UHFGOMfvCDH+jrX/+6MjMzJUnNzc2SpISEhKC+CQkJgWXNzc2KiIjQqFGjztmnt7KyMsXHxwceKSkpF1s2AAAYBC46oCxevFjvvPOOtmzZ0meZx+MJem6M6dPW2/n6rFixQq2trYHHoUOHLrZsAAAwCFxUQFmyZIl+85vf6I033tAVV1wRaE9MTJSkPiMhLS0tgVGVxMREdXZ26tixY+fs01tkZKTi4uKCHgAAYOgKKaAYY7R48WJVVFTo9ddfV1paWtDytLQ0JSYmavv27YG2zs5O7dy5Uzk5OZKk7OxsjRgxIqhPU1OT6urqAn0AAMDwFh5K50WLFmnz5s168cUXFRsbGxgpiY+PV1RUlDwej0pKSlRaWqqMjAxlZGSotLRU0dHRKi4uDvS96667tHTpUo0ZM0ajR4/WsmXLlJWVpZkzZw78JwQAAINOSAHliSeekCTl5eUFtT/11FO68847JUnLly+Xz+fTPffco2PHjmnq1Knatm2bYmNjA/3XrVun8PBw3XrrrfL5fJoxY4Y2btwor9d7aZ8GAAAMCZd0HRS3cB0UYOjiOijA0PW5XQcFAADgs0BAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOuEu10AAHfV19ervb3d7TICDhw4EPTTJrGxscrIyHC7DGBYIKAAw1h9fb2uvPJKt8vo1+233+52Cf364IMPCCnA54CAAgxj/pGTTZs2afLkyS5X4/D5fGpsbFRqaqqioqLcLifgwIEDuv32260abQKGMgIKAE2ePFlTpkxxu4yA6667zu0SALiMSbIAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOuFuFwDAPZ4zp/SVxDBFffKBdITvK+cT9ckH+kpimDxnTrldCjAsEFCAYWzk8f/S3gWXSW8ukN50uxq7TZa0d8FlOnD8vyTluF0OMOQRUIBh7NRlEzTlZ8f1q1/9SpMnTXK7HKsdeO89ffvb39aTN0xwuxRgWCCgAMOYCR+pPzZ3y/c/rpSSr3G7HKv5mrv1x+ZumfCRbpcCDAscdAYAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1gk5oLz55puaN2+ekpOT5fF4VFlZGbTcGKNVq1YpOTlZUVFRysvL0/79+4P6dHR0aMmSJRo7dqxiYmJ000036fDhw5f0QQAAwNARckA5ceKEvvzlL2v9+vX9Ln/44Ye1du1arV+/Xnv27FFiYqKuv/56tbe3B/qUlJTohRde0NatW7Vr1y4dP35cc+fOVVdX18V/EgAAMGSEfC+eOXPmaM6cOf0uM8bo0Ucf1X333afCwkJJ0tNPP62EhARt3rxZCxYsUGtrq5588kk9++yzmjlzpiRp06ZNSklJ0WuvvabZs2dfwscBEIqTJ09Kkvbu3etyJT18Pp8aGxuVmpqqqKgot8sJOHDggNslAMPKgN4ssKGhQc3NzZo1a1agLTIyUtOnT9fu3bu1YMEC1dbW6vTp00F9kpOTlZmZqd27d/cbUDo6OtTR0RF43tbWNpBlA8PWe++9J0n63ve+53Ilg0dsbKzbJQDDwoAGlObmZklSQkJCUHtCQoI+/PDDQJ+IiAiNGjWqTx//63srKyvTAw88MJClApBUUFAgSZo0aZKio6PdLea/HThwQLfffrs2bdqkyZMnu11OkNjYWGVkZLhdBjAsDGhA8fN4PEHPjTF92no7X58VK1boBz/4QeB5W1ubUlJSLr1QYJgbO3asvvvd77pdRr8mT56sKVOmuF0GAJcM6GnGiYmJktRnJKSlpSUwqpKYmKjOzk4dO3bsnH16i4yMVFxcXNADAAAMXQMaUNLS0pSYmKjt27cH2jo7O7Vz507l5ORIkrKzszVixIigPk1NTaqrqwv0AQAAw1vIh3iOHz+ugwcPBp43NDRo3759Gj16tCZMmKCSkhKVlpYqIyNDGRkZKi0tVXR0tIqLiyVJ8fHxuuuuu7R06VKNGTNGo0eP1rJly5SVlRU4qwcAAAxvIQeUt99+W/n5+YHn/rkh8+fP18aNG7V8+XL5fD7dc889OnbsmKZOnapt27YFzXxft26dwsPDdeutt8rn82nGjBnauHGjvF7vAHwkAAAw2HmMMcbtIkLV1tam+Ph4tba2Mh8FGGL27t2r7Oxs1dbWMkkWGGJC2X9zLx4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA64S7XQCAoeHkyZN67733Lnk9Bw4cCPo5ECZNmqTo6OgBWx+Azx4BBcCAeO+995SdnT1g67v99tsHbF21tbWaMmXKgK0PwGePgAJgQEyaNEm1tbWXvB6fz6fGxkalpqYqKipqACpzagMwuHiMMcbtIkLV1tam+Ph4tba2Ki4uzu1yAADABQhl/80kWQAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWCXe7gIvhvwFzW1uby5UAAIAL5d9v+/fj5zMoA0p7e7skKSUlxeVKAABAqNrb2xUfH3/ePh5zITHGMt3d3Tpy5IhiY2Pl8XjcLgfAAGpra1NKSooOHTqkuLg4t8sBMICMMWpvb1dycrLCws4/y2RQBhQAQ1dbW5vi4+PV2tpKQAGGMSbJAgAA6xBQAACAdQgoAKwSGRmp+++/X5GRkW6XAsBFzEEBAADWYQQFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgArPDmm29q3rx5Sk5OlsfjUWVlpdslAXARAQWAFU6cOKEvf/nLWr9+vdulALDAoLybMYChZ86cOZozZ47bZQCwBCMoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsw1k8AKxw/PhxHTx4MPC8oaFB+/bt0+jRozVhwgQXKwPgBo8xxrhdBADs2LFD+fn5fdrnz5+vjRs3fv4FAXAVAQUAAFiHOSgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsM7/B0ks38PVKGnvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in num_col:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df_test[col])\n",
    "    plt.title('Boxplot of {}'.format(col), color = 'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a701e2",
   "metadata": {},
   "source": [
    "#### Finding the number of outliers in each numerical columns of testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae3d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outliers in the column ApplicantIncome  is 32\n",
      "The outliers in the column CoapplicantIncome  is 8\n",
      "The outliers in the column LoanAmount  is 18\n",
      "The outliers in the column Loan_Amount_Term  is 50\n",
      "The outliers in the column Credit_History  is 59\n"
     ]
    }
   ],
   "source": [
    "for col in num_col:\n",
    "    Q1 = df_test[col].quantile(0.25)\n",
    "    Q3 = df_test[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - (1.5 * IQR)\n",
    "    upp = Q3 + (1.5 * IQR)\n",
    "    outliers = []\n",
    "    for x in df_test[col]:\n",
    "        if(x > upp) or (x < low):\n",
    "            outliers.append(x)\n",
    "    print('The outliers in the column', col, ' is', len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071651c",
   "metadata": {},
   "source": [
    "###### <font color = violet> For the record, we are not removing the outliers from the testing dataset also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4cdd0",
   "metadata": {},
   "source": [
    "#### Getting the number of unique values in the column 'Loan_ID' of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cedeb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Loan_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a94569",
   "metadata": {},
   "source": [
    "#### Getting the number of unique values in the column 'Loan_ID' of testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b95ca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Loan_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9184b4",
   "metadata": {},
   "source": [
    "###### <font color = violet> We can see that there is no similar values in the 'Loan_ID' columns in both training and testing datasets. So we can drop the 'Loan_ID' column from both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dea3e7",
   "metadata": {},
   "source": [
    "### <font color = brown> Setting the feature training and testing variables, and target training variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baebc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['Loan_Status', 'Loan_ID'], axis = 1)\n",
    "x_test = df_test.drop('Loan_ID', axis = 1)\n",
    "y_train = df_train['Loan_Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f471d9",
   "metadata": {},
   "source": [
    "## <font color = brown>  One Hot Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19aab3e",
   "metadata": {},
   "source": [
    "#### One hot encoding x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "747955c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Married_No</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>Education_Graduate</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>Self_Employed_No</th>\n",
       "      <th>Self_Employed_Yes</th>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0       128.0             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History  Gender_Female  Gender_Male  Married_No  Married_Yes  \\\n",
       "0             1.0              0            1           1            0   \n",
       "1             1.0              0            1           0            1   \n",
       "2             1.0              0            1           0            1   \n",
       "3             1.0              0            1           0            1   \n",
       "4             1.0              0            1           1            0   \n",
       "\n",
       "   Dependents_0  Dependents_1  Dependents_2  Dependents_3+  \\\n",
       "0             1             0             0              0   \n",
       "1             0             1             0              0   \n",
       "2             1             0             0              0   \n",
       "3             1             0             0              0   \n",
       "4             1             0             0              0   \n",
       "\n",
       "   Education_Graduate  Education_Not Graduate  Self_Employed_No  \\\n",
       "0                   1                       0                 1   \n",
       "1                   1                       0                 1   \n",
       "2                   1                       0                 0   \n",
       "3                   0                       1                 1   \n",
       "4                   1                       0                 1   \n",
       "\n",
       "   Self_Employed_Yes  Property_Area_Rural  Property_Area_Semiurban  \\\n",
       "0                  0                    0                        0   \n",
       "1                  0                    1                        0   \n",
       "2                  1                    0                        0   \n",
       "3                  0                    0                        0   \n",
       "4                  0                    0                        0   \n",
       "\n",
       "   Property_Area_Urban  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.get_dummies(x_train)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb6272",
   "metadata": {},
   "source": [
    "#### One hot encoding x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "103e2240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Married_No</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>Education_Graduate</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>Self_Employed_No</th>\n",
       "      <th>Self_Employed_Yes</th>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5720                  0       110.0             360.0   \n",
       "1             3076               1500       126.0             360.0   \n",
       "2             5000               1800       208.0             360.0   \n",
       "3             2340               2546       100.0             360.0   \n",
       "4             3276                  0        78.0             360.0   \n",
       "\n",
       "   Credit_History  Gender_Female  Gender_Male  Married_No  Married_Yes  \\\n",
       "0             1.0              0            1           0            1   \n",
       "1             1.0              0            1           0            1   \n",
       "2             1.0              0            1           0            1   \n",
       "3             1.0              0            1           0            1   \n",
       "4             1.0              0            1           1            0   \n",
       "\n",
       "   Dependents_0  Dependents_1  Dependents_2  Dependents_3+  \\\n",
       "0             1             0             0              0   \n",
       "1             0             1             0              0   \n",
       "2             0             0             1              0   \n",
       "3             0             0             1              0   \n",
       "4             1             0             0              0   \n",
       "\n",
       "   Education_Graduate  Education_Not Graduate  Self_Employed_No  \\\n",
       "0                   1                       0                 1   \n",
       "1                   1                       0                 1   \n",
       "2                   1                       0                 1   \n",
       "3                   1                       0                 1   \n",
       "4                   0                       1                 1   \n",
       "\n",
       "   Self_Employed_Yes  Property_Area_Rural  Property_Area_Semiurban  \\\n",
       "0                  0                    0                        0   \n",
       "1                  0                    0                        0   \n",
       "2                  0                    0                        0   \n",
       "3                  0                    0                        0   \n",
       "4                  0                    0                        0   \n",
       "\n",
       "   Property_Area_Urban  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.get_dummies(x_test)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe9718",
   "metadata": {},
   "source": [
    "# <font color = brown> Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe1a94",
   "metadata": {},
   "source": [
    "#### Importing Logistic regression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77466f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af0c5b",
   "metadata": {},
   "source": [
    "#### Loading the sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e53d48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cb7f2",
   "metadata": {},
   "source": [
    "#### Loading the head of the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "009cb3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Loan_Status\n",
       "0  LP001015           N\n",
       "1  LP001022           N\n",
       "2  LP001031           N\n",
       "3  LP001035           N\n",
       "4  LP001051           N"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1992c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy = sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79827a",
   "metadata": {},
   "source": [
    "#### Importing RandomizedSearchCV from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9e4a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43ac81",
   "metadata": {},
   "source": [
    "#### Creating parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c452b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2', 'elasticnet', None]\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "multi_class = ['auto', 'ovr', 'multinomial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fca8bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_random_grid = {'penalty' : penalty,\n",
    "                 'solver' : solver,\n",
    "                 'multi_class': multi_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9a05ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ffb23",
   "metadata": {},
   "source": [
    "#### Tuning with Randomized Search CV for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bbef390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV] END .........multi_class=auto, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....multi_class=auto, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .....multi_class=auto, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=auto, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=auto, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END .multi_class=auto, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .multi_class=auto, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .multi_class=auto, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=elasticnet, solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..multi_class=auto, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..multi_class=auto, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..multi_class=auto, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .......multi_class=auto, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......multi_class=auto, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......multi_class=auto, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=None, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...multi_class=auto, penalty=None, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...multi_class=auto, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...multi_class=auto, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=auto, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END .........multi_class=auto, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END ........multi_class=auto, penalty=None, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.17406e-27): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.62043e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.27309e-26): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........multi_class=auto, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END ........multi_class=auto, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=ovr, penalty=l1, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........multi_class=ovr, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ...........multi_class=ovr, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......multi_class=ovr, penalty=l2, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ......multi_class=ovr, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ......multi_class=ovr, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ............multi_class=ovr, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ...........multi_class=ovr, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ...........multi_class=ovr, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ...........multi_class=ovr, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=ovr, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...multi_class=ovr, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...multi_class=ovr, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...multi_class=ovr, penalty=elasticnet, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........multi_class=ovr, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........multi_class=ovr, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........multi_class=ovr, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....multi_class=ovr, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=ovr, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=None, solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.17406e-27): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.62043e-25): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=9.27309e-26): result may not be accurate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........multi_class=ovr, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END ..........multi_class=ovr, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END .........multi_class=ovr, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END .........multi_class=ovr, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END .........multi_class=ovr, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l1, solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...multi_class=multinomial, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ...multi_class=multinomial, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ...multi_class=multinomial, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ....multi_class=multinomial, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV] END ...multi_class=multinomial, penalty=l2, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...multi_class=multinomial, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ...multi_class=multinomial, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=liblinear; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cg; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END multi_class=multinomial, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END ..multi_class=multinomial, penalty=None, solver=sag; total time=   0.0s\n",
      "[CV] END .multi_class=multinomial, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END .multi_class=multinomial, penalty=None, solver=saga; total time=   0.0s\n",
      "[CV] END .multi_class=multinomial, penalty=None, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "111 fits failed out of a total of 216.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver newton-cholesky does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.80459908        nan        nan        nan 0.68566874\n",
      " 0.79479515 0.80459908 0.80296509 0.80296509 0.68566874 0.68566874\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79154312        nan 0.79970509 0.79154312 0.68566874 0.68566874\n",
      "        nan 0.80459908        nan        nan        nan 0.68566874\n",
      " 0.79479515 0.80459908 0.80296509 0.80296509 0.68566874 0.68566874\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79154312        nan 0.79970509 0.79154312 0.68566874 0.68566874\n",
      "        nan        nan        nan        nan        nan 0.68566874\n",
      " 0.79316117        nan 0.8013311         nan 0.68404272 0.68566874\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.77528296        nan 0.79970509        nan 0.68404272 0.68566874]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={&#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                                   &#x27;newton-cg&#x27;,\n",
       "                                                   &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={&#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                                   &#x27;newton-cg&#x27;,\n",
       "                                                   &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={'multi_class': ['auto', 'ovr',\n",
       "                                                        'multinomial'],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    None],\n",
       "                                        'solver': ['lbfgs', 'liblinear',\n",
       "                                                   'newton-cg',\n",
       "                                                   'newton-cholesky', 'sag',\n",
       "                                                   'saga']},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_randomcv = RandomizedSearchCV(estimator = logic, param_distributions = lr_random_grid, n_iter = 100, cv =3, verbose = 2, n_jobs = 1)\n",
    "lr_randomcv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77c91d",
   "metadata": {},
   "source": [
    "#### Displaying best estimator for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82dada87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a9819",
   "metadata": {},
   "source": [
    "#### Predicting with best estimator of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eb88ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_random = lr_randomcv.best_estimator_\n",
    "y_best_pred_lr = lr_best_random.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe0997",
   "metadata": {},
   "source": [
    "#### Replacing the 'Loan_Status' column with the prediction values from logistic regression after tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2f48795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Loan_Status'] = y_best_pred_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab05392",
   "metadata": {},
   "source": [
    "#### Saving the logistic regression prediction model dataset after tuning as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44ac1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\logistic_regression_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbea18",
   "metadata": {},
   "source": [
    "###### <font color = violet> The Logistic regression model after fine tuning has accuracy about 0.7847."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814be81",
   "metadata": {},
   "source": [
    "# <font color = brown> k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3da92e",
   "metadata": {},
   "source": [
    "#### Importing KNeighborsClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f52ea6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b651dd5",
   "metadata": {},
   "source": [
    "#### Creating parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cd8688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = np.arange(3,15)\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size = [int(i) for i in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "metric = ['minkowski', 'euclidean', 'manhattan', 'haversine']\n",
    "p = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e82b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random_grid = {'n_neighbors' : n_neighbors,\n",
    "                  'algorithm' : algorithm,\n",
    "                  'leaf_size' : leaf_size,\n",
    "                  'metric' : metric,\n",
    "                  'p' : p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a5162e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f9a4263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=4, p=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=5, p=2; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=minkowski, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=minkowski, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=minkowski, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=manhattan, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=manhattan, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=manhattan, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=haversine, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=haversine, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=haversine, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=manhattan, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=10, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=manhattan, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=manhattan, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=manhattan, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=90, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=90, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=90, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=minkowski, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=minkowski, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=minkowski, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=30, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=8, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=8, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=euclidean, n_neighbors=8, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=haversine, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=haversine, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=haversine, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=euclidean, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=euclidean, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=euclidean, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=euclidean, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=euclidean, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=euclidean, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=euclidean, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=manhattan, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=manhattan, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=manhattan, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=haversine, n_neighbors=10, p=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=brute, leaf_size=50, metric=haversine, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=haversine, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=80, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=40, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=40, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=40, metric=haversine, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=euclidean, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=euclidean, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=euclidean, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=haversine, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, metric=manhattan, n_neighbors=9, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=3, p=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=manhattan, n_neighbors=3, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=minkowski, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=minkowski, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=minkowski, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=50, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=minkowski, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=minkowski, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=90, metric=minkowski, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=14, p=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=brute, leaf_size=30, metric=haversine, n_neighbors=14, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=minkowski, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=minkowski, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=4, p=1; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=80, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=minkowski, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=minkowski, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=100, metric=minkowski, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=minkowski, n_neighbors=7, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=14, p=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=haversine, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=haversine, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=8, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=30, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=30, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=30, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=manhattan, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=manhattan, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=manhattan, n_neighbors=5, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=60, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=60, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=60, metric=euclidean, n_neighbors=13, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=70, metric=euclidean, n_neighbors=5, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=9, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=50, metric=euclidean, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=6, p=2; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=90, metric=minkowski, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=euclidean, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=euclidean, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=60, metric=euclidean, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=minkowski, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=minkowski, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=minkowski, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=70, metric=manhattan, n_neighbors=6, p=1; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=manhattan, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=manhattan, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=40, metric=manhattan, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=20, metric=minkowski, n_neighbors=3, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=40, metric=euclidean, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=haversine, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=100, metric=manhattan, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=70, metric=haversine, n_neighbors=12, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=haversine, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=haversine, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=70, metric=haversine, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 649, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n",
      "    return ArgKmin64.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 87, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\", line 93, in sklearn.metrics._pairwise_distances_reduction._datasets_pair.DatasetsPair64.get_for\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=kd_tree, leaf_size=30, metric=euclidean, n_neighbors=6, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=90, metric=haversine, n_neighbors=11, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=20, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=20, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=20, metric=haversine, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=10, metric=minkowski, n_neighbors=10, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=80, metric=haversine, n_neighbors=4, p=1; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=50, metric=minkowski, n_neighbors=4, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=manhattan, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=manhattan, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, leaf_size=10, metric=manhattan, n_neighbors=7, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=60, metric=manhattan, n_neighbors=14, p=2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "48 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 493, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'haversine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 646, in _fit\n",
      "    self._tree = BallTree(\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 853, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 2607, in sklearn.metrics._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.61070461        nan 0.63355651 0.6709788         nan        nan\n",
      " 0.55369839        nan 0.67262873 0.59446039 0.66449864        nan\n",
      " 0.67425474 0.57976247 0.60421648 0.58797226 0.67425474 0.56180456\n",
      "        nan 0.58309421 0.57651044 0.56180456 0.64982465 0.63355651\n",
      " 0.66611669        nan 0.66611669 0.59766459 0.64495457 0.60585047\n",
      " 0.58797226        nan 0.65633668 0.65797864 0.57976247        nan\n",
      " 0.59446039        nan 0.64984856 0.59446039 0.56180456 0.59766459\n",
      " 0.58797226        nan 0.63355651 0.57813646        nan        nan\n",
      " 0.56180456 0.65633668        nan 0.58309421 0.64982465        nan\n",
      " 0.57976247 0.63681652 0.6709788  0.55369839        nan 0.63189064\n",
      "        nan 0.65797864 0.67425474 0.56180456        nan 0.56180456\n",
      " 0.66611669 0.64984856 0.63515862        nan 0.58309421        nan\n",
      " 0.59446039 0.66449864 0.61070461 0.66449864 0.60421648 0.58309421\n",
      " 0.64495457 0.64984856 0.58309421 0.67100271 0.66611669 0.58797226\n",
      " 0.55369839 0.55369839 0.57976247 0.63681652        nan 0.55369839\n",
      "        nan        nan 0.58309421        nan        nan 0.63355651\n",
      "        nan 0.56180456 0.63515862 0.6709788 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;,\n",
       "                                                      &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                                        &#x27;leaf_size&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100],\n",
       "                                        &#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;,\n",
       "                                                   &#x27;manhattan&#x27;, &#x27;haversine&#x27;],\n",
       "                                        &#x27;n_neighbors&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        &#x27;p&#x27;: [1, 2]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;,\n",
       "                                                      &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                                        &#x27;leaf_size&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100],\n",
       "                                        &#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;,\n",
       "                                                   &#x27;manhattan&#x27;, &#x27;haversine&#x27;],\n",
       "                                        &#x27;n_neighbors&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        &#x27;p&#x27;: [1, 2]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_iter=100, n_jobs=1,\n",
       "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
       "                                                      'kd_tree', 'brute'],\n",
       "                                        'leaf_size': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100],\n",
       "                                        'metric': ['minkowski', 'euclidean',\n",
       "                                                   'manhattan', 'haversine'],\n",
       "                                        'n_neighbors': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'p': [1, 2]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_randomcv = RandomizedSearchCV(estimator = knn, param_distributions = knn_random_grid, n_iter = 100, cv =3, verbose = 2, n_jobs = 1)\n",
    "knn_randomcv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30218120",
   "metadata": {},
   "source": [
    "#### Displaying best estimator randomcv for knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdf81f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=10, metric=&#x27;manhattan&#x27;, n_neighbors=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=10, metric=&#x27;manhattan&#x27;, n_neighbors=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(leaf_size=10, metric='manhattan', n_neighbors=13)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52dd4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_random = knn_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2878d",
   "metadata": {},
   "source": [
    "#### Importing GridSearchCV from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "668e47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae8afb",
   "metadata": {},
   "source": [
    "#### Creating parameter for GirdSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03e34d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {'n_neighbors' : [knn_randomcv.best_params_['n_neighbors']-3,\n",
    "                              knn_randomcv.best_params_['n_neighbors']-2,\n",
    "                              knn_randomcv.best_params_['n_neighbors']-1,\n",
    "                              knn_randomcv.best_params_['n_neighbors']],\n",
    "              'algorithm' : [knn_randomcv.best_params_['algorithm']],\n",
    "              'leaf_size' : [knn_randomcv.best_params_['leaf_size'],\n",
    "                            knn_randomcv.best_params_['leaf_size']+10],\n",
    "              'metric' : [knn_randomcv.best_params_['metric']],\n",
    "              'p' : [knn_randomcv.best_params_['p']]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8005ecbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=10, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=10, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=11, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=12, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=20, metric=manhattan, n_neighbors=13, p=2; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;], &#x27;leaf_size&#x27;: [10, 20],\n",
       "                         &#x27;metric&#x27;: [&#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [10, 11, 12, 13], &#x27;p&#x27;: [2]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;], &#x27;leaf_size&#x27;: [10, 20],\n",
       "                         &#x27;metric&#x27;: [&#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [10, 11, 12, 13], &#x27;p&#x27;: [2]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(), n_jobs=1,\n",
       "             param_grid={'algorithm': ['auto'], 'leaf_size': [10, 20],\n",
       "                         'metric': ['manhattan'],\n",
       "                         'n_neighbors': [10, 11, 12, 13], 'p': [2]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_knn = GridSearchCV(estimator = knn, param_grid = param_grid_knn, cv = 10, n_jobs = 1, verbose =2)\n",
    "grid_search_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f2a01",
   "metadata": {},
   "source": [
    "#### Displaying best estimator gridcv for knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c967811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=10, metric=&#x27;manhattan&#x27;, n_neighbors=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=10, metric=&#x27;manhattan&#x27;, n_neighbors=11)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(leaf_size=10, metric='manhattan', n_neighbors=11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1022ad",
   "metadata": {},
   "source": [
    "#### Predicting with best estimator of knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ea77171",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_knn = grid_search_knn.best_estimator_\n",
    "y_best_pred_knn = best_grid_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a3ff1",
   "metadata": {},
   "source": [
    "#### Replacing the 'Loan_Status' column with the prediction values from knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c783dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Loan_Status'] = y_best_pred_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063e60d",
   "metadata": {},
   "source": [
    "#### Saving the knn prediction model dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5fa00493",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\knn_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0797e",
   "metadata": {},
   "source": [
    "###### <font color = violet> The knn model after fine tuning has accuracy about 0.6875."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f62054",
   "metadata": {},
   "source": [
    "# <font color = brown> Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc527269",
   "metadata": {},
   "source": [
    "#### Importing Decision Tree from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd5db5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581eab65",
   "metadata": {},
   "source": [
    "#### Creating parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27be06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['entropy', 'gini', 'log_loss']\n",
    "max_features = ['sqrt', 'auto', 'log2']\n",
    "max_depth = [int(i) for i in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "min_samples_split = [2,5,10,14]\n",
    "min_samples_leaf = [1,2,4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3166c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random_grid = {'criterion' : criterion,\n",
    "                 'max_features' : max_features,\n",
    "                 'max_depth' : max_depth,\n",
    "                 'min_samples_split' : min_samples_split,\n",
    "                 'min_samples_leaf' : min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c225d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8925dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=6, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=6, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=14; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini',\n",
       "                                                      'log_loss'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['sqrt', 'auto',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_randomcv = RandomizedSearchCV(estimator = dt, param_distributions = dt_random_grid, n_iter = 100, cv =3, verbose = 2, n_jobs = 1)\n",
    "dt_randomcv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b9392",
   "metadata": {},
   "source": [
    "#### Displaying best estimator randomcv for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06a98414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=230, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_leaf=8, min_samples_split=14)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=230, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_leaf=8, min_samples_split=14)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=230, max_features='auto',\n",
       "                       min_samples_leaf=8, min_samples_split=14)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e34fc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_random = dt_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967a002",
   "metadata": {},
   "source": [
    "#### Creating parameter for GirdSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b5e77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion' : [dt_randomcv.best_params_['criterion']],\n",
    "    'max_depth' : [dt_randomcv.best_params_['max_depth']],\n",
    "    'max_features' : [dt_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf' : [dt_randomcv.best_params_['min_samples_leaf'],\n",
    "                          dt_randomcv.best_params_['min_samples_leaf']+2,\n",
    "                          dt_randomcv.best_params_['min_samples_leaf']+4],\n",
    "    'min_samples_split' : [dt_randomcv.best_params_['min_samples_split']-2,\n",
    "                           dt_randomcv.best_params_['min_samples_split']-1,\n",
    "                           dt_randomcv.best_params_['min_samples_split'],\n",
    "                           dt_randomcv.best_params_['min_samples_split']+1,\n",
    "                           dt_randomcv.best_params_['min_samples_split']+2]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4659535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=10, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=12; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=13; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=14; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=15; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=12, min_samples_split=16; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;], &#x27;max_depth&#x27;: [230],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [8, 10, 12],\n",
       "                         &#x27;min_samples_split&#x27;: [12, 13, 14, 15, 16]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;], &#x27;max_depth&#x27;: [230],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [8, 10, 12],\n",
       "                         &#x27;min_samples_split&#x27;: [12, 13, 14, 15, 16]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [230],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [8, 10, 12],\n",
       "                         'min_samples_split': [12, 13, 14, 15, 16]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dt = GridSearchCV(estimator = dt, param_grid = param_grid_dt, cv = 10, n_jobs = 1, verbose = 2)\n",
    "grid_search_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306941c",
   "metadata": {},
   "source": [
    "#### Displaying best estimator gridcv for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d68b84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=230, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_leaf=12, min_samples_split=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=230, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_leaf=12, min_samples_split=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=230, max_features='auto',\n",
       "                       min_samples_leaf=12, min_samples_split=15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce374c",
   "metadata": {},
   "source": [
    "#### Predicting with best estimator of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "237b45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_dt = grid_search_dt.best_estimator_\n",
    "y_best_pred_dt = best_grid_dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528e131",
   "metadata": {},
   "source": [
    "#### Replacing the 'Loan_Status' column with the prediction values from decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "18bda398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Loan_Status'] = y_best_pred_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97d6e6",
   "metadata": {},
   "source": [
    "#### Saving the decision tree prediction model dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "367f66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\decision_tree_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ca183",
   "metadata": {},
   "source": [
    "###### <font color = violet> The decision tree model after fine tuning has accuracy about 0.6667."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee07172",
   "metadata": {},
   "source": [
    "# <font color = brown> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b864c6",
   "metadata": {},
   "source": [
    "#### Importing Random Forest from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3d6a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1abaae",
   "metadata": {},
   "source": [
    "#### Creating parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b1fb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['entropy', 'gini', 'log_loss']\n",
    "max_features = ['sqrt', 'auto', 'log2']\n",
    "max_depth = [int(i) for i in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "min_samples_split = [2,5,10,14]\n",
    "min_samples_leaf = [1,2,4,6,8]\n",
    "n_estimators = [int(i) for i in np.linspace(start = 200, stop = 2000, num = 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "733d6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_grid = {'criterion' : criterion,\n",
    "                 'max_features' : max_features,\n",
    "                 'max_depth' : max_depth,\n",
    "                 'min_samples_split' : min_samples_split,\n",
    "                 'min_samples_leaf' : min_samples_leaf,\n",
    "                 'n_estimators' : n_estimators\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b590723",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48f4f5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1052; total time=   3.3s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1052; total time=   3.3s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1526; total time=   4.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1526; total time=   4.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1526; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1621; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1621; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1621; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=578; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=578; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1621; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1621; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1621; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1431; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1431; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1431; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   3.8s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1242; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1242; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1242; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1905; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1905; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1905; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=389; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=389; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=389; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   4.9s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=auto, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=auto, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=auto, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1147; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1147; total time=   3.3s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1621; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1621; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=1621; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=389; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=389; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=389; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1431; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1431; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1431; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=768; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=768; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=768; total time=   2.3s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   5.5s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   5.5s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=578; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1431; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1431; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1431; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=1052; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=1052; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=1052; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=578; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=578; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1242; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1242; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1242; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=1242; total time=   5.0s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   3.1s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   3.1s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1052; total time=   3.1s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1810; total time=   5.6s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1810; total time=   5.6s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1810; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=768; total time=   2.3s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=768; total time=   2.3s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=768; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.0s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=14, n_estimators=389; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=14, n_estimators=389; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=14, n_estimators=389; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   4.0s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=1336; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=863; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=863; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=863; total time=   2.5s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1526; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1526; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1526; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1147; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1147; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=957; total time=   2.8s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=957; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=957; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=484; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=484; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=484; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=8, min_samples_split=14, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=863; total time=   2.6s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=863; total time=   2.7s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=863; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1905; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1905; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1905; total time=   5.3s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1905; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1905; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1905; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=768; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=768; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=768; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1715; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1715; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1715; total time=   5.2s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1147; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1147; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1147; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1242; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1242; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1242; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1431; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1431; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1431; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1810; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1810; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1810; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1147; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1147; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1147; total time=   4.4s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1052; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1052; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=2000; total time=   7.3s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1431; total time=   4.9s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1431; total time=   5.6s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1431; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1052; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1052; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1052; total time=   4.0s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=484; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=484; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=484; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   6.1s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1810; total time=   6.1s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=2000; total time=   6.3s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=2000; total time=   6.3s\n",
      "[CV] END criterion=log_loss, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=2000; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=673; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=578; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=1336; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=1336; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=1336; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=863; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1715; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1715; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1715; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1336; total time=   4.2s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=484; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=484; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=484; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   5.2s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1621; total time=   5.2s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1715; total time=   5.4s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1715; total time=   5.6s\n",
      "[CV] END criterion=log_loss, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1715; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1621; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1621; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1621; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=673; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=673; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=673; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1052; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1052; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1052; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1621; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1621; total time=   5.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=1621; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=294; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=294; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=294; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=294; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=294; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=484; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=768; total time=   2.9s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=768; total time=   2.8s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=768; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1810; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1810; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=1810; total time=   6.7s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1242; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1242; total time=   5.7s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1242; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1715; total time=   6.5s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1715; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1715; total time=   5.4s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1336; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1336; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1336; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1052; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1052; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1052; total time=   3.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=450, max_features=auto, min_samples_leaf=8, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1621; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1621; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=1621; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=1242; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=1242; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=1242; total time=   3.4s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1336; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1810; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1810; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1810; total time=   6.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 294, 389, 484,\n",
       "                                                         578, 673, 768, 863,\n",
       "                                                         957, 1052, 1147, 1242,\n",
       "                                                         1336, 1431, 1526, 1621,\n",
       "                                                         1715, 1810, 1905,\n",
       "                                                         2000]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;auto&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10, 14],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 294, 389, 484,\n",
       "                                                         578, 673, 768, 863,\n",
       "                                                         957, 1052, 1147, 1242,\n",
       "                                                         1336, 1431, 1526, 1621,\n",
       "                                                         1715, 1810, 1905,\n",
       "                                                         2000]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini',\n",
       "                                                      'log_loss'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['sqrt', 'auto',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 294, 389, 484,\n",
       "                                                         578, 673, 768, 863,\n",
       "                                                         957, 1052, 1147, 1242,\n",
       "                                                         1336, 1431, 1526, 1621,\n",
       "                                                         1715, 1810, 1905,\n",
       "                                                         2000]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv = RandomizedSearchCV(estimator = rf, param_distributions = rf_random_grid, n_iter = 100, cv =3, verbose = 2, n_jobs = 1)\n",
    "rf_randomcv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb49c9",
   "metadata": {},
   "source": [
    "#### Displaying best estimator randomcv for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f720f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=670, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_split=14, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=670, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_split=14, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=670, max_features='auto',\n",
       "                       min_samples_split=14, n_estimators=200)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6695df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_random = rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580bd2e",
   "metadata": {},
   "source": [
    "#### Creating parameter for GirdSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42a51ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'criterion' : [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth' : [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features' : [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf' : [rf_randomcv.best_params_['min_samples_leaf']-4,\n",
    "                          rf_randomcv.best_params_['min_samples_leaf']-2,\n",
    "                          rf_randomcv.best_params_['min_samples_leaf'],\n",
    "                          rf_randomcv.best_params_['min_samples_leaf']+2,\n",
    "                          rf_randomcv.best_params_['min_samples_leaf']+4],\n",
    "    'min_samples_split' : [rf_randomcv.best_params_['min_samples_split']-2,\n",
    "                           rf_randomcv.best_params_['min_samples_split']-1,\n",
    "                           rf_randomcv.best_params_['min_samples_split'],\n",
    "                           rf_randomcv.best_params_['min_samples_split']+1,\n",
    "                           rf_randomcv.best_params_['min_samples_split']+2],\n",
    "    'n_estimators' : [rf_randomcv.best_params_['n_estimators']-200,\n",
    "                      rf_randomcv.best_params_['n_estimators']-100,\n",
    "                      rf_randomcv.best_params_['n_estimators'],\n",
    "                      rf_randomcv.best_params_['n_estimators']+100,\n",
    "                      rf_randomcv.best_params_['n_estimators']+200,]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0b8f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 125 candidates, totalling 1250 fits\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-3, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=12, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=13, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=14, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=15, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=300; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=-1, min_samples_split=16, n_estimators=400; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=13, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=14, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=16, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=12, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=13, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=3, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=12, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=13, n_estimators=400; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=14, n_estimators=400; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=15, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=0; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=670, max_features=auto, min_samples_leaf=5, min_samples_split=16, n_estimators=400; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "650 fits failed out of a total of 1250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got -3 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got -1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.79817557 0.80631941 0.80304072\n",
      " 0.80140137        nan 0.80631941 0.80140137 0.80631941 0.80468006\n",
      "        nan 0.80142782 0.80631941 0.80304072 0.80631941        nan\n",
      " 0.80304072 0.80468006 0.80468006 0.80468006        nan 0.80468006\n",
      " 0.80468006 0.80957166 0.80468006        nan 0.80631941 0.80631941\n",
      " 0.80631941 0.80631941        nan 0.80468006 0.80957166 0.80631941\n",
      " 0.80631941        nan 0.80631941 0.80631941 0.80631941 0.80631941\n",
      "        nan 0.80631941 0.80793231 0.80631941 0.80631941        nan\n",
      " 0.80631941 0.80631941 0.80631941 0.80631941        nan 0.80957166\n",
      " 0.80957166 0.80957166 0.80957166        nan 0.80957166 0.80957166\n",
      " 0.80957166 0.80957166        nan 0.80793231 0.80957166 0.80957166\n",
      " 0.80957166        nan 0.80957166 0.80957166 0.80957166 0.80957166\n",
      "        nan 0.80957166 0.80795875 0.80957166 0.80957166]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;log_loss&#x27;], &#x27;max_depth&#x27;: [670],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [-3, -1, 1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [12, 13, 14, 15, 16],\n",
       "                         &#x27;n_estimators&#x27;: [0, 100, 200, 300, 400]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;log_loss&#x27;], &#x27;max_depth&#x27;: [670],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [-3, -1, 1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [12, 13, 14, 15, 16],\n",
       "                         &#x27;n_estimators&#x27;: [0, 100, 200, 300, 400]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={'criterion': ['log_loss'], 'max_depth': [670],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [-3, -1, 1, 3, 5],\n",
       "                         'min_samples_split': [12, 13, 14, 15, 16],\n",
       "                         'n_estimators': [0, 100, 200, 300, 400]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(estimator = rf, param_grid = param_grid_rf, cv = 10, n_jobs = 1, verbose =2)\n",
    "grid_search_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd983b",
   "metadata": {},
   "source": [
    "#### Displaying best estimator gridcv for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acc913d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=670, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_split=16, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=670, max_features=&#x27;auto&#x27;,\n",
       "                       min_samples_split=16, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=670, max_features='auto',\n",
       "                       min_samples_split=16, n_estimators=300)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bfab0",
   "metadata": {},
   "source": [
    "#### Predicting with best estimator of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94a17b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_rf = grid_search_rf.best_estimator_\n",
    "y_best_pred_rf = best_grid_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397dc87",
   "metadata": {},
   "source": [
    "#### Replacing the 'Loan_Status' column with the prediction values from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "70a24ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Loan_Status'] = y_best_pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede5cd9",
   "metadata": {},
   "source": [
    "#### Saving the random forest prediction model dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "158335c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\random_forest_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28971cb",
   "metadata": {},
   "source": [
    "###### <font color = violet> The random forest model after fine tuning has accuracy about 0.7778."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2520e",
   "metadata": {},
   "source": [
    "# <font color = brown> SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e4af1",
   "metadata": {},
   "source": [
    "#### Importing SVC from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c409ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63e817",
   "metadata": {},
   "source": [
    "#### Predicting with svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "87ae5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(x_train, y_train)\n",
    "y_pred_svc = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d52591",
   "metadata": {},
   "source": [
    "#### Replacing the 'Loan_Status' column with the prediction values from random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df8fcf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Loan_Status'] = y_pred_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8727e0",
   "metadata": {},
   "source": [
    "#### Saving the svc prediction model dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e61f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"D:\\ICTAK\\Virtual Competitions\\2\\svc_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e23c5",
   "metadata": {},
   "source": [
    "###### <font color = violet> The svc model after fine tuning has accuracy about 0.7569."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65c345",
   "metadata": {},
   "source": [
    "### <font color = red> The logistic regression model has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a20bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
